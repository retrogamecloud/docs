---
title: Procedimientos de Recuperaci贸n Ante Desastres
description: Gu铆a completa de disaster recovery con procedimientos paso a paso, RPO/RTO
  definidos, simulacros de DR y escenarios de desastre documentados
icon: shield-halved
---

# Procedimientos de Recuperaci贸n ante Desastres

Esta gu铆a establece los procedimientos completos de recuperaci贸n ante desastres (DR) para la plataforma RetroGameCloud, incluyendo objetivos de tiempo y punto de recuperaci贸n, procedimientos detallados, escenarios espec铆ficos y validaciones.

## Objetivos de Recuperaci贸n

### Definiciones Clave

<Card title="RPO - Recovery Point Objective" icon="clock">
  **1 hora** - P茅rdida m谩xima de datos aceptable
</Card>

<Card title="RTO - Recovery Time Objective" icon="stopwatch">
  **4 horas** - Tiempo m谩ximo para restaurar servicios
</Card>

### Matriz de Criticidad

| Componente | RPO | RTO | Prioridad |
|------------|-----|-----|-----------|
| Base de Datos (PostgreSQL) | 1 hora | 30 min | Cr铆tica |
| Aplicaciones (EKS) | 1 hora | 2 horas | Alta |
| Configuraci贸n Kong | 1 hora | 1 hora | Alta |
| CDN/Frontend | 4 horas | 1 hora | Media |
| Redis Cache | 4 horas | 30 min | Media |

## Arquitectura de Backup

```mermaid
graph TB
    A[Producci贸n Madrid] --> B[Snapshots RDS]
    A --> C[Backup S3 Cross-Region]
    A --> D[Git Repository]
    A --> E[Terraform State S3]

    B --> F[Regi贸n DR Frankfurt]
    C --> F
    D --> F
    E --> F

    F --> G[RDS Restaurado]
    F --> H[EKS Cluster]
    F --> I[Kong Config]
    F --> J[Aplicaciones]

    style A fill:#ff9999
    style F fill:#99ff99
```

## Escenarios de Desastre

### Escenario 1: P茅rdida Total de Regi贸n AWS

<Card title="P茅rdida Regi贸n AWS Madrid (eu-west-1)" icon="cloud-exclamation">

**S铆ntomas:**
- Todos los servicios AWS en eu-west-1 inaccesibles
- Timeout en conexiones a RDS, EKS, y S3
- Dashboard AWS muestra regi贸n indisponible

**Impacto:** Sistema completamente inoperativo

**Procedimiento de Recuperaci贸n:**

<Tabs>
  <Tab title="1. Activaci贸n DR">
    ```bash
    # Activar regi贸n de disaster recovery
    export DR_REGION="eu-central-1"
    export PRIMARY_REGION="eu-west-1"

    # Verificar conectividad a regi贸n DR
    aws ec2 describe-regions --region $DR_REGION

    # Activar infraestructura DR con Terraform
    cd terraform/disaster-recovery
    terraform workspace select dr-frankfurt
    terraform apply -auto-approve
    ```
  </Tab>

  <Tab title="2. Restaurar Base de Datos">
    ```bash
    # Encontrar 煤ltimo snapshot cross-region
    LATEST_SNAPSHOT=$(aws rds describe-db-snapshots \
      --region $DR_REGION \
      --db-instance-identifier retrogame-prod \
      --query 'DBSnapshots[0].DBSnapshotIdentifier' \
      --output text)

    # Restaurar RDS desde snapshot
    aws rds restore-db-instance-from-db-snapshot \
      --db-instance-identifier retrogame-dr \
      --db-snapshot-identifier $LATEST_SNAPSHOT \
      --region $DR_REGION
    ```
  </Tab>

  <Tab title="3. Desplegar Aplicaciones">
    ```bash
    # Configurar kubectl para cluster DR
    aws eks update-kubeconfig \
      --region $DR_REGION \
      --name retrogame-dr

    # Desplegar aplicaciones desde GitOps
    kubectl apply -f k8s/production/
    
    # Verificar pods en ejecuci贸n
    kubectl get pods -A
    ```
  </Tab>
</Tabs>

**RTO Esperado:** 3-4 horas
**RPO Esperado:** 1 hora m谩ximo

</Card>

### Escenario 2: Corrupci贸n de Base de Datos

<Card title="Corrupci贸n BBDD PostgreSQL" icon="database">

**S铆ntomas:**
- Errores de conexi贸n a base de datos
- Consultas SQL fallan con errores de corrupci贸n
- Logs muestran errores de integridad de datos

**Impacto:** P茅rdida de funcionalidad dependiente de BBDD

**Procedimiento de Recuperaci贸n:**

<Tabs>
  <Tab title="1. Diagn贸stico">
    ```bash
    # Verificar estado de RDS
    aws rds describe-db-instances \
      --db-instance-identifier retrogame-prod

    # Revisar logs de PostgreSQL
    aws logs get-log-events \
      --log-group-name /aws/rds/instance/retrogame-prod/postgresql

    # Test de conectividad b谩sica
    psql -h $DB_ENDPOINT -U retrogame_user -d retrogame_db -c "\l"
    ```
  </Tab>

  <Tab title="2. Point-in-Time Recovery">
    ```bash
    # Identificar timestamp antes de la corrupci贸n
    RECOVERY_TIME="2024-01-15T10:30:00Z"

    # Crear nueva instancia desde point-in-time
    aws rds restore-db-instance-to-point-in-time \
      --source-db-instance-identifier retrogame-prod \
      --target-db-instance-identifier retrogame-recovery \
      --restore-time $RECOVERY_TIME
    ```
  </Tab>

  <Tab title="3. Validaci贸n y Switchover">
    ```bash
    # Validar integridad de datos restaurados
    psql -h $RECOVERY_ENDPOINT -c "SELECT COUNT(*) FROM users;"
    psql -h $RECOVERY_ENDPOINT -c "SELECT COUNT(*) FROM games;"

    # Actualizar configuraci贸n de aplicaciones
    kubectl patch configmap db-config \
      --patch '{"data":{"DB_HOST":"'$RECOVERY_ENDPOINT'"}}'

    # Reiniciar pods para aplicar cambios
    kubectl rollout restart deployment/retrogame-api
    ```
  </Tab>
</Tabs>

**RTO Esperado:** 30-60 minutos
**RPO Esperado:** Variable seg煤n timestamp de recovery

</Card>

### Escenario 3: Compromiso de Seguridad

<Card title="Compromiso de Seguridad / Breach" icon="shield-exclamation">

**S铆ntomas:**
- Actividad sospechosa en logs
- Acceso no autorizado detectado
- Alertas de seguridad en AWS GuardDuty

**Impacto:** Sistema comprometido, datos en riesgo

**Procedimiento de Recuperaci贸n:**

<Tabs>
  <Tab title="1. Contenci贸n Inmediata">
    ```bash
    # Aislar cluster EKS
    aws eks update-cluster-config \
      --name retrogame-prod \
      --resources-vpc-config endpointConfigPrivateAccess=true,endpointConfigPublicAccess=false

    # Rotar todas las credenciales
    aws iam create-access-key --user-name retrogame-service
    aws secretsmanager rotate-secret --secret-id retrogame/db-credentials

    # Revisar y revocar sesiones activas
    aws sts get-caller-identity
    ```
  </Tab>

  <Tab title="2. An谩lisis Forense">
    ```bash
    # Exportar logs para an谩lisis
    aws logs create-export-task \
      --log-group-name /aws/eks/retrogame-prod/cluster \
      --from-time $(date -d '24 hours ago' +%s)000 \
      --to $(date +%s)000 \
      --destination retrogame-security-logs

    # Snapshot de instancias para preservar evidencia
    aws ec2 create-snapshot \
      --volume-id vol-xxxxx \
      --description "Security incident forensic snapshot"
    ```
  </Tab>

  <Tab title="3. Reconstrucci贸n Limpia">
    ```bash
    # Desplegar infraestructura limpia en regi贸n DR
    cd terraform/disaster-recovery
    terraform apply -var="security_incident=true"

    # Restaurar datos desde backup verificado limpio
    CLEAN_SNAPSHOT="retrogame-clean-backup-$(date -d '48 hours ago' +%Y%m%d)"
    aws rds restore-db-instance-from-db-snapshot \
      --db-snapshot-identifier $CLEAN_SNAPSHOT
    ```
  </Tab>
</Tabs>

**RTO Esperado:** 4-6 horas
**RPO Esperado:** Hasta 48 horas (煤ltimo backup verificado limpio)

</Card>

### Escenario 4: Fallo del Cluster EKS

<Card title="Fallo Cluster EKS" icon="layer-group">

**S铆ntomas:**
- Nodes del cluster no responden
- API Server de Kubernetes inaccesible
- Pods en estado "Unknown" o "NotReady"

**Impacto:** Aplicaciones no disponibles

**Procedimiento de Recuperaci贸n:**

<Tabs>
  <Tab title="1. Diagn贸stico del Cluster">
    ```bash
    # Verificar estado del cluster
    aws eks describe-cluster --name retrogame-prod

    # Revisar nodes
    kubectl get nodes -o wide

    # Verificar eventos del cluster
    kubectl get events --sort-by='.lastTimestamp' -A
    ```
  </Tab>

  <Tab title="2. Recuperaci贸n de Nodes">
    ```bash
    # Reiniciar node groups
    aws eks update-nodegroup-config \
      --cluster-name retrogame-prod \
      --nodegroup-name retrogame-workers \
      --scaling-config minSize=0,maxSize=10,desiredSize=0

    # Escalar de nuevo
    aws eks update-nodegroup-config \
      --cluster-name retrogame-prod \
      --nodegroup-name retrogame-workers \
      --scaling-config minSize=2,maxSize=10,desiredSize=3
    ```
  </Tab>

  <Tab title="3. Redeployment de Aplicaciones">
    ```bash
    # Forzar recreaci贸n de deployments
    kubectl delete deployment --all -n default
    kubectl apply -f k8s/production/

    # Verificar estado de pods
    kubectl get pods -A
    kubectl describe pods -l app=retrogame-api
    ```
  </Tab>
</Tabs>

**RTO Esperado:** 1-2 horas
**RPO Esperado:** M铆nimo (datos en RDS intactos)

</Card>

### Escenario 5: P茅rdida de Datos Redis

<Card title="P茅rdida Cache Redis / ElastiCache" icon="memory">

**S铆ntomas:**
- Conexiones Redis fallan
- Performance degradado por falta de cache
- Logs muestran errores de conexi贸n a Redis

**Impacto:** Degradaci贸n de performance, algunas funcionalidades limitadas

**Procedimiento de Recuperaci贸n:**

<Tabs>
  <Tab title="1. Evaluaci贸n de Redis">
    ```bash
    # Verificar estado del cluster Redis
    aws elasticache describe-cache-clusters \
      --cache-cluster-id retrogame-redis

    # Test conectividad
    redis-cli -h $REDIS_ENDPOINT ping

    # Verificar snapshots disponibles
    aws elasticache describe-snapshots \
      --cache-cluster-id retrogame-redis
    ```
  </Tab>

  <Tab title="2. Restauraci贸n desde Snapshot">
    ```bash
    # Crear nuevo cluster desde snapshot
    LATEST_SNAPSHOT=$(aws elasticache describe-snapshots \
      --query 'Snapshots[0].SnapshotName' --output text)

    aws elasticache create-cache-cluster \
      --cache-cluster-id retrogame-redis-recovery \
      --snapshot-name $LATEST_SNAPSHOT \
      --cache-node-type cache.r6g.large
    ```
  </Tab>

  <Tab title="3. Failover y Warming">
    ```bash
    # Actualizar configuraci贸n de aplicaciones
    kubectl patch configmap redis-config \
      --patch '{"data":{"REDIS_HOST":"'$NEW_REDIS_ENDPOINT'"}}'

    # Reiniciar aplicaciones
    kubectl rollout restart deployment/retrogame-api

    # Script de warming de cache
    kubectl apply -f k8s/jobs/cache-warming-job.yaml
    ```
  </Tab>
</Tabs>

**RTO Esperado:** 30 minutos
**RPO Esperado:** ltima backup autom谩tica (m谩ximo 24h)

</Card>

## Procedimiento General de Disaster Recovery

### Fase 1: Evaluaci贸n y Activaci贸n

<Tabs>
  <Tab title="Evaluaci贸n Inicial">
    ```bash
    # Verificar estado de la regi贸n primaria
    aws ec2 describe-regions --region eu-west-1
    aws rds describe-db-instances --region eu-west-1
    aws eks describe-cluster --name retrogame-prod --region eu-west-1

    # Comprobar 煤ltimo snapshot disponible
    aws rds describe-db-snapshots \
      --db-instance-identifier retrogame-prod \
      --snapshot-type automated \
      --query 'DBSnapshots[0]'
    ```
  </Tab>

  <Tab title="Decisi贸n de Activaci贸n">
    ```bash
    # Checklist de activaci贸n DR
    echo "1. 驴Regi贸n primaria completamente inaccesible? [y/n]"
    echo "2. 驴RTO/RPO en riesgo de no cumplirse? [y/n]"
    echo "3. 驴Equipo DR notificado y disponible? [y/n]"
    echo "4. 驴Stakeholders informados? [y/n]"

    # Si todas las respuestas son 'y', proceder con DR
    ```
  </Tab>

  <Tab title="Comunicaci贸n">
    ```bash
    # Notificar inicio de procedimiento DR
    curl -X POST $SLACK_WEBHOOK \
      -d '{"text":" DISASTER RECOVERY ACTIVATED - Incident #DR-001"}'

    # Actualizar p谩gina de status
    curl -X POST "https://api.statuspage.io/v1/pages/xxx/incidents" \
      -H "Authorization: OAuth xxx" \
      -d '{"incident": {"name": "Service Disruption - DR in Progress"}}'
    ```
  </Tab>
</Tabs>

### Fase 2: Recuperaci贸n de Infraestructura

<Tabs>
  <Tab title="Terraform DR">
    ```bash
    # Cambiar a workspace de DR
    cd infrastructure/terraform
    terraform workspace select disaster-recovery

    # Aplicar configuraci贸n DR
    terraform apply \
      -var="enable_dr=true" \
      -var="snapshot_id=$LATEST_SNAPSHOT_ID" \
      -auto-approve

    # Verificar recursos creados
    terraform output
    ```
  </Tab>

  <Tab title="Base de Datos">
    ```bash
    # Esperar a que RDS est茅 disponible
    aws rds wait db-instance-available \
      --db-instance-identifier retrogame-dr

    # Actualizar security groups
    aws ec2 authorize-security-group-ingress \
      --group-id $DR_SG_ID \
      --protocol tcp \
      --port 5
</Tab>
</Tabs>
```