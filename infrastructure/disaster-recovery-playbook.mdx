---
title: 4.6 Procedimientos de Recuperaci√≥n Ante Desastres
description: Gu√≠a completa de disaster recovery con procedimientos paso a paso, RPO/RTO
  definidos por servicio, runbooks de recuperaci√≥n detallados y programa de simulacros
  trimestrales incluyendo 5 escenarios cr√≠ticos espec√≠ficos
icon: shield-halved
---

# 4.6 Procedimientos de Recuperaci√≥n ante Desastres

Esta gu√≠a establece los procedimientos completos de recuperaci√≥n ante desastres (DR) para la plataforma RetroGameCloud, incluyendo objetivos de tiempo y punto de recuperaci√≥n espec√≠ficos por servicio, runbooks detallados de recuperaci√≥n y programa de simulacros.

## 4.6.1 Objetivos de Recuperaci√≥n Detallados

### Definiciones Clave

<Card title="RPO - Recovery Point Objective" icon="clock">
  **Variable por servicio** - P√©rdida m√°xima de datos aceptable seg√∫n criticidad
</Card>

<Card title="RTO - Recovery Time Objective" icon="stopwatch">
  **Variable por servicio** - Tiempo m√°ximo para restaurar servicios seg√∫n prioridad
</Card>

<Card title="MTTR - Mean Time To Recovery" icon="wrench">
  **Tiempo promedio real** - M√©trica hist√≥rica de recuperaci√≥n
</Card>

### Matriz de Criticidad y Objetivos por Servicio

| Servicio | RPO | RTO | MTTR* | Prioridad | Dependencias | Notas |
|----------|-----|-----|-------|-----------|--------------|-------|
| **PostgreSQL RDS** | 5 min | 15 min | 12 min | P0-Cr√≠tica | Ninguna | Multi-AZ + Read Replicas |
| **EKS Control Plane** | 10 min | 20 min | 18 min | P0-Cr√≠tica | VPC, IAM | Cluster distribuido |
| **API Gateway (Kong)** | 15 min | 25 min | 20 min | P0-Cr√≠tica | EKS, RDS | Load balancer activo |
| **Redis ElastiCache** | 30 min | 10 min | 8 min | P1-Alta | Ninguna | Cluster mode enabled |
| **Core Applications** | 15 min | 45 min | 35 min | P1-Alta | EKS, RDS, Redis | Microservicios cr√≠ticos |
| **Frontend/CDN** | 1 hora | 30 min | 25 min | P1-Alta | S3, CloudFront | Assets est√°ticos |
| **Monitoring Stack** | 30 min | 1 hora | 45 min | P2-Media | EKS | Prometheus, Grafana |
| **Logging (ELK)** | 2 horas | 2 horas | 90 min | P2-Media | EKS | Elasticsearch cluster |
| **CI/CD Pipeline** | 4 horas | 3 horas | 2.5 horas | P3-Baja | GitHub, EKS | Jenkins/ArgoCD |
| **Development Env** | 24 horas | 8 horas | 6 horas | P3-Baja | Todos | No cr√≠tico |

*MTTR basado en simulacros trimestrales de los √∫ltimos 12 meses

## 4.6.2 Escenarios Cr√≠ticos de Recuperaci√≥n

### Escenario 1: Fallo Total de RDS PostgreSQL

<Card title="Criticidad: P0 - Servicio Cr√≠tico" icon="database">
  **Impacto:** P√©rdida total de acceso a datos de aplicaci√≥n
  **RPO:** 5 minutos | **RTO:** 15 minutos
</Card>

#### Detecci√≥n y S√≠ntomas
- CloudWatch Alarms: `RDS-DB-Connection-Failed`
- Aplicaciones reportan errores de conexi√≥n DB
- Dashboards muestran 0 conexiones activas
- Health checks fallan en endpoints `/health/db`

#### Procedimiento de Recuperaci√≥n

**Paso 1: Evaluaci√≥n Inicial (2 minutos)**
```bash
# Verificar estado del RDS
aws rds describe-db-instances --db-instance-identifier retrogame-prod-db

# Comprobar eventos recientes
aws rds describe-events --source-identifier retrogame-prod-db --duration 60
```

**Paso 2: Activaci√≥n de Read Replica (5 minutos)**
```bash
# Promover read replica a instancia principal
aws rds promote-read-replica \
  --db-instance-identifier retrogame-prod-db-replica-1

# Verificar estado de promoci√≥n
aws rds describe-db-instances \
  --db-instance-identifier retrogame-prod-db-replica-1 \
  --query 'DBInstances[0].DBInstanceStatus'
```

**Paso 3: Actualizaci√≥n de Aplicaciones (5 minutos)**
```bash
# Actualizar ConfigMaps con nueva URL de DB
kubectl patch configmap app-config -p '{"data":{"DB_HOST":"retrogame-prod-db-replica-1.xyz.rds.amazonaws.com"}}'

# Reiniciar pods de aplicaci√≥n
kubectl rollout restart deployment/game-api
kubectl rollout restart deployment/user-service
kubectl rollout restart deployment/leaderboard-service
```

**Paso 4: Verificaci√≥n y Monitoreo (3 minutos)**
```bash
# Verificar conectividad
kubectl exec -it deploy/game-api -- pg_isready -h $DB_HOST

# Comprobar m√©tricas de aplicaci√≥n
curl -s https://api.retrogame.cloud/health | jq '.database.status'
```

### Escenario 2: Ca√≠da Total de Regi√≥n AWS

<Card title="Criticidad: P0 - Desastre Regional" icon="globe">
  **Impacto:** P√©rdida completa de todos los servicios en regi√≥n primaria
  **RPO:** 15 minutos | **RTO:** 2 horas
</Card>

#### Detecci√≥n y S√≠ntomas
- M√∫ltiples servicios AWS inaccesibles
- CloudWatch dashboard sin datos
- Site24x7 reporta downtime total
- Ping a ELB timeout

#### Procedimiento de Recuperaci√≥n

**Paso 1: Activaci√≥n de Regi√≥n Secundaria (15 minutos)**
```bash
# Cambiar contexto a regi√≥n de DR
export AWS_DEFAULT_REGION=eu-west-1
export KUBE_CONTEXT=retrogame-dr-cluster

# Verificar estado del cluster DR
kubectl config use-context $KUBE_CONTEXT
kubectl get nodes
```

**Paso 2: Recuperaci√≥n de Base de Datos (30 minutos)**
```bash
# Restaurar desde √∫ltimo snapshot cross-region
LATEST_SNAPSHOT=$(aws rds describe-db-snapshots \
  --db-instance-identifier retrogame-prod-db \
  --snapshot-type automated \
  --query 'DBSnapshots[-1].DBSnapshotIdentifier' \
  --output text)

aws rds restore-db-instance-from-db-snapshot \
  --db-instance-identifier retrogame-dr-db \
  --db-snapshot-identifier $LATEST_SNAPSHOT
```

**Paso 3: Despliegue de Aplicaciones (45 minutos)**
```bash
# Aplicar configuraciones de DR
kubectl apply -f manifests/dr-environment/

# Esperar a que DB est√© disponible
while ! kubectl exec -it deploy/game-api -- pg_isready -h $DR_DB_HOST; do
  sleep 30
done

# Ejecutar migraciones necesarias
kubectl exec -it deploy/game-api -- npm run db:migrate
```

**Paso 4: Configuraci√≥n de DNS y CDN (20 minutos)**
```bash
# Actualizar Route53 a regi√≥n DR
aws route53 change-resource-record-sets \
  --hosted-zone-id Z1234567890 \
  --change-batch file://dr-dns-changes.json

# Invalidar CloudFront cache
aws cloudfront create-invalidation \
  --distribution-id E1234567890 \
  --paths "/*"
```

**Paso 5: Verificaci√≥n Completa (10 minutos)**
```bash
# Test de extremo a extremo
curl -X POST https://api.retrogame.cloud/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username":"testuser","password":"testpass"}'

# Verificar m√©tricas clave
kubectl get pods -A | grep -v Running
```

### Escenario 3: Corrupci√≥n de Datos Cr√≠ticos

<Card title="Criticidad: P1 - Integridad de Datos" icon="triangle-exclamation">
  **Impacto:** Datos inconsistentes o corruptos en producci√≥n
  **RPO:** 30 minutos | **RTO:** 1 hora
</Card>

#### Detecci√≥n y S√≠ntomas
- Usuarios reportan puntuaciones incorrectas
- Aplicaci√≥n muestra errores de integridad referencial
- Logs muestran constraint violations
- Data quality checks fallan

#### Procedimiento de Recuperaci√≥n

**Paso 1: Aislamiento Inmediato (5 minutos)**
```bash
# Activar modo mantenimiento
kubectl patch configmap app-config -p '{"data":{"MAINTENANCE_MODE":"true"}}'
kubectl rollout restart deployment/game-api

# Crear snapshot de emergencia
aws rds create-db-snapshot \
  --db-instance-identifier retrogame-prod-db \
  --db-snapshot-identifier emergency-$(date +%Y%m%d-%H%M%S)
```

**Paso 2: An√°lisis de Corrupci√≥n (15 minutos)**
```bash
# Conectar a DB para diagn√≥stico
kubectl exec -it deploy/database-tools -- psql -h $DB_HOST -U postgres

# Ejecutar queries de diagn√≥stico
SELECT schemaname, tablename, attname, n_distinct, correlation 
FROM pg_stats 
WHERE schemaname = 'public' AND n_distinct < -0.1;

# Verificar integridad referencial
\i /scripts/data-integrity-check.sql
```

**Paso 3: Recuperaci√≥n Selectiva (30 minutos)**
```bash
# Identificar timestamp de √∫ltima consistencia
RECOVERY_POINT=$(kubectl exec -it deploy/game-api -- \
  node scripts/find-last-consistent-point.js)

# Crear instancia temporal desde snapshot
aws rds restore-db-instance-to-point-in-time \
  --source-db-instance-identifier retrogame-prod-db \
  --target-db-instance-identifier retrogame-temp-recovery \
  --restore-time $RECOVERY_POINT

# Exportar datos consistentes
pg_dump -h retrogame-temp-recovery.xyz.rds.amazonaws.com \
  -U postgres -t users -t games -t scores \
  --data-only > clean-data.sql
```

**Paso 4: Restauraci√≥n y Validaci√≥n (10 minutos)**
```bash
# Restaurar datos limpios
kubectl exec -i deploy/database-tools -- \
  psql -h $DB_HOST -U postgres < clean-data.sql

# Ejecutar validaciones
kubectl exec -it deploy/game-api -- npm run validate:data

# Desactivar modo mantenimiento
kubectl patch configmap app-config -p '{"data":{"MAINTENANCE_MODE":"false"}}'
```

### Escenario 4: P√©rdida Total de Cluster EKS

<Card title="Criticidad: P0 - Infraestructura Cr√≠tica" icon="server">
  **Impacto:** Todos los servicios aplicativos inaccesibles
  **RPO:** 10 minutos | **RTO:** 45 minutos
</Card>

#### Detecci√≥n y S√≠ntomas
- `kubectl` commands timeout
- API server no responde
- Worker nodes unreachable
- LoadBalancer health checks fallan

#### Procedimiento de Recuperaci√≥n

**Paso 1: Evaluaci√≥n de Da√±o (5 minutos)**
```bash
# Intentar conexi√≥n al cluster
kubectl cluster-info

# Verificar estado en AWS Console
aws eks describe-cluster --name retrogame-prod --region us-west-2

# Comprobar nodes
aws ec2 describe-instances --filters "Name=tag:kubernetes.io/cluster/retrogame-prod,Values=owned"
```

**Paso 2: Recreaci√≥n de Cluster (25 minutos)**
```bash
# Ejecutar Terraform para recrear cluster
cd infrastructure/terraform
terraform plan -target=module.eks_cluster
terraform apply -target=module.eks_cluster -auto-approve

# Configurar kubectl context
aws eks update-kubeconfig --name retrogame-prod --region us-west-2
```

**Paso 3: Restauraci√≥n de Aplicaciones (10 minutos)**
```bash
# Aplicar configuraciones base
kubectl apply -f k8s/infrastructure/

# Esperar a que infrastructure est√© ready
kubectl wait --for=condition=ready pod -l app=kong-gateway --timeout=300s
kubectl wait --for=condition=ready pod -l app=prometheus --timeout=300s

# Desplegar aplicaciones
kubectl apply -f k8s/applications/
```

**Paso 4: Verificaci√≥n de Servicios (5 minutos)**
```bash
# Verificar todos los pods
kubectl get pods -A | grep -v Running

# Test de conectividad
curl -f https://api.retrogame.cloud/health

# Verificar m√©tricas
curl -f https://monitoring.retrogame.cloud/api/v1/query?query=up
```

### Escenario 5: Compromiso de Seguridad

<Card title="Criticidad: P0 - Incidente de Seguridad" icon="shield-exclamation">
  **Impacto:** Potencial exposici√≥n de datos sensibles y sistemas
  **RPO:** Inmediato | **RTO:** Variable seg√∫n alcance
</Card>

#### Detecci√≥n y S√≠ntomas
- Alertas de seguridad autom√°ticas
- Accesos no autorizados en logs
- Comportamiento an√≥malo en aplicaciones
- Notificaci√≥n de usuarios sobre actividad sospechosa

#### Procedimiento de Recuperaci√≥n

**Paso 1: Contenci√≥n Inmediata (2 minutos)**
```bash
# Activar modo lockdown
kubectl patch configmap app-config -p '{"data":{"SECURITY_LOCKDOWN":"true"}}'

# Revocar todas las sesiones activas
kubectl exec -it deploy/redis-cli -- redis-cli FLUSHDB

# Bloquear acceso externo
aws ec2 authorize-security-group-ingress \
  --group-id sg-12345678 \
  --protocol tcp --port 443 \
  --source-group sg-internal-only
```

**Paso 2: An√°lisis Forense (15 minutos)**
```bash
# Crear snapshots para an√°lisis
aws rds create-db-snapshot \
  --db-instance-identifier retrogame-prod-db \
  --db-snapshot-identifier forensic-$(date +%Y%m%d-%H%M%S)

# Exportar logs cr√≠ticos
kubectl logs -l app=game-api --since=24h > /tmp/forensic-app-logs.log
kubectl logs -l app=kong-gateway --since=24h > /tmp/forensic-gateway-logs.log

# Revisar accesos SSH
aws ec2 describe-instances --filters "Name=key-name,Values=*" \
  --query 'Reservations[].Instances[].[InstanceId,KeyName,LaunchTime]'
```

**Paso 3: Limpieza y Fortalecimiento (30 minutos)**
```bash
# Rotar todas las credenciales
aws secretsmanager rotate-secret --secret-id prod/database/password
aws secretsmanager rotate-secret --secret-id prod/api/jwt-secret
aws secretsmanager rotate-secret --secret-id prod/redis/auth-token

# Actualizar im√°genes de contenedores
kubectl set image deployment/game-api \
  game-api=retrogame/game-api:$(date +%Y%m%d)-secure
kubectl set image deployment/user-service \
  user-service=retrogame/user-service:$(date +%Y%m%d)-secure

# Aplicar parches de seguridad
kubectl apply -f k8s/security/enhanced-policies.yaml
```

**Paso 4: Restauraci√≥n Controlada (Variable)**
```bash
# Crear entorno de staging para validaci√≥n
terraform apply -var="environment=security-validation"

# Ejecutar tests de penetraci√≥n
kubectl exec -it deploy/security-scanner -- \
  nmap -sS -A api.retrogame.cloud

# Restauraci√≥n gradual por servicio
for service in user-service game-api leaderboard; do
  kubectl patch deployment $service -p '{"spec":{"replicas":1}}'
  kubectl wait --for=condition=ready pod -l app=$service --timeout=300s
  # Ejecutar tests espec√≠ficos del servicio
  curl -f https://api.retrogame.cloud/health/$service
  sleep 60
done

# Desactivar modo lockdown tras validaci√≥n completa
kubectl patch configmap app-config -p '{"data":{"SECURITY_LOCKDOWN":"false"}}'
```

**Paso 5: Post-Incidente (Continuo)**
```bash
# Habilitar logging extendido
kubectl patch configmap fluent-bit-config \
  --patch '{"data":{"audit.conf":"[INPUT]\n    Name audit\n    Path /var/log/audit/*"}}'

# Configurar alertas mejoradas
kubectl apply -f monitoring/enhanced-security-rules.yaml

# Programar revisi√≥n completa de accesos
echo "Security review scheduled for $(date -d '+24 hours')" | \
  kubectl create configmap security-review-reminder --from-literal=reminder=-
```

## 4.6.3 Runbooks de Recuperaci√≥n

### Comunicaci√≥n Durante Incidentes

<Card title="Escalaci√≥n y Comunicaci√≥n" icon="bullhorn">
```
1. Detecci√≥n ‚Üí Slack #incidents (autom√°tico)
2. P0/P1 ‚Üí Llamada al Team Lead (inmediato)
3. >30min ‚Üí Comunicaci√≥n a stakeholders
4. >1h ‚Üí Status page p√∫blico actualizado
```
</Card>

### Matriz de Responsabilidades

| Rol | P0 (Cr√≠tico) | P1 (Alto) | P2 (Medio) | P3 (Bajo) |
|-----|--------------|-----------|------------|-----------|
| **SRE On-Call** | Respuesta inmediata | 15 min | 1 hora | 4 horas |
| **Tech Lead** | Notificado inmediato | 30 min | 2 horas | Pr√≥ximo d√≠a laboral |
| **DevOps Team** | Todo el equipo | Lead + 1 | Lead + 1 | Lead |
| **Stakeholders** | CEO, CTO | CTO | Product Manager | - |

## 4.6.4 Programa de Simulacros

### Calendario Trimestral de DR Drills

```mermaid
gantt
    title Programa de Simulacros DR 2024
    dateFormat  YYYY-MM-DD
    section Q1 2024
    DB Failover Drill          :active, 2024-01-15, 1d
    Security Incident Sim      :2024-02-15, 1d
    Full Region Failover       :2024-03-15, 1d
    section Q2 2024
    EKS Recovery Drill         :2024-04-15, 1d
    Data Corruption Sim        :2024-05-15, 1d
    Multi-Service Outage       :2024-06-15, 1d
    section Q3 2024
    DB Failover + App Recovery :2024-07-15, 1d
    Network Isolation Drill    :2024-08-15, 1d
    Complete DR Scenario       :2024-09-15, 1d
    section Q4 2024
    Holiday Season Prep        :2024-10-15, 1d
    Security + Recovery        :2024-11-15, 1d
    Year-End Full Test         :2024-12-15, 1d
```

### M√©tricas de Simulacros

| Escenario | Q4 2023 | Q1 2024 | Q2 2024 | Objetivo | Estado |
|-----------|---------|---------|---------|----------|--------|
| **DB Failover** | 18 min | 15 min | 12 min | <15 min | ‚úÖ Cumplido |
| **Region Switch** | 3.2 h | 2.8 h | 2.1 h | <2 h | üü° En progreso |
| **EKS Recovery** | 52 min | 48 min | 35 min | <45 min | ‚úÖ Cumplido |
| **Security Response** | 45 min | 38 min | 28 min | <30 min | ‚úÖ Cumplido |
| **Data Recovery** | 95 min | 82 min | 65 min | <60 min | üü° En progreso |

## 4.6.5 Herramientas y Automation

### Scripts de Automatizaci√≥n

```bash
# /opt/dr-scripts/
‚îú‚îÄ‚îÄ db-failover.sh              # Automatiza promoci√≥n de replica
‚îú‚îÄ‚îÄ cluster-rebuild.sh          # Recreaci√≥n completa de EKS
‚îú‚îÄ‚îÄ security-lockdown.sh        # Procedimientos de contenci√≥n
‚îú‚îÄ‚îÄ region-switch.sh            # Cambio completo de regi√≥n
‚îú‚îÄ‚îÄ data-consistency-check.sh   # Validaci√≥n integridad datos
‚îî‚îÄ‚îÄ post-recovery-validation.sh # Tests post-recuperaci√≥n
```

### Dashboards de DR

<Card title="Monitoring Dashboard" icon="chart-line">
- **RTO/RPO Tracking**: Seguimiento en tiempo real de objetivos
- **Recovery Status**: Estado actual de todos los sistemas
- **Simulation Results**: Hist√≥rico de simulacros y m√©tricas
- **Dependency Map**: Visualizaci√≥n de dependencias cr√≠ticas
</Card>

### Alertas Autom√°ticas

```yaml
# prometheus-rules.yaml
groups:
  - name: disaster-recovery
    rules:
    - alert: DatabasePrimaryDown
      expr: up{job="postgres-primary"} == 0
      for: 30s
      labels:
        severity: critical
        playbook: "db-failover.sh"
      annotations:
        summary: "Primary database is down - initiating automatic failover"
        
    - alert: RegionalOutage
      expr: up{region="us-west-2"} == 0
      for: 2m
      labels:
        severity: critical
        playbook: "region-switch.sh"
      annotations:
        summary: "Regional outage detected - consider DR activation"
```

## 4.6.6 Post-Recovery y Lessons Learned

### Checklist Post-Incidente

- [ ] Validaci√≥n completa de funcionalidad
- [ ] Verificaci√≥n de integridad de datos
- [ ] Actualizaci√≥n de documentaci√≥n
- [ ] Post-mortem meeting programado
- [ ] Comunicaci√≥n de resoluci√≥n a stakeholders
- [ ] Revisi√≥n de m√©tricas RTO/RPO reales
- [ ] Identificaci√≥n de mejoras en procesos

### Template de Post-Mortem

```markdown
# Post-Mortem: [Tipo de Incidente] - [Fecha]

## Resumen Ejecutivo
- Duraci√≥n total: X horas Y minutos
- RPO Real: X minutos
- RTO Real: X minutos
- Servicios afectados: [Lista]

## Timeline Detallado
[Cronolog√≠a exacta del incidente y recuperaci√≥n]

## Root Cause Analysis
[Causa ra√≠z identificada]

## Qu√© funcion√≥ bien
[Aspectos positivos del proceso de recuperaci√≥n]

## Qu√© se puede mejorar
[√Åreas de mejora identificadas]

## Action Items
- [ ] [Acci√≥n] - Responsable: [Persona] - Fecha l√≠mite: [Fecha]
```

---

<Card title="Contactos de Emergencia 24/7" icon="phone">
**SRE On-Call:** +1-555-DR-TEAMS  
**Incident Commander:** +1-555-COMMAND  
**AWS Support Enterprise:** Case escalation via console  
**Security Team:** security-emergency@retrogame.cloud
</Card>

*√öltima actualizaci√≥n: Diciembre 2024 | Pr√≥xima revisi√≥n: Marzo 2025*