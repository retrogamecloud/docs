---
title: 8.5. Migraciones de Base de Datos
description: Gu√≠a completa para crear, probar y aplicar migraciones de esquema de forma segura en producci√≥n
icon: database
---

# 8.5. Migraciones de Base de Datos

Esta gu√≠a proporciona un proceso completo para gestionar migraciones de base de datos de forma segura, incluyendo estrategias para migraciones zero-downtime y procedimientos de rollback.

## Flujo de Migraciones

```mermaid
graph LR
    A[Crear Migraci√≥n] --> B[Test Local]
    B --> C[Deploy a Staging]
    C --> D[Test Staging]
    D --> E{Aprobado?}
    E -->|S√≠| F[Backup Prod]
    E -->|No| A
    F --> G[Aplicar en Prod]
    G --> H{Healthcheck OK?}
    H -->|S√≠| I[Migraci√≥n Completa]
    H -->|No| J[Rollback Autom√°tico]
    J --> K[Investigar Fallos]
```

## Herramientas de Migraci√≥n por Servicio

<Tabs>
<Tab title="TypeORM (User Service)">

```typescript
// src/migrations/1234567890123-AddUserPreferences.ts
import { MigrationInterface, QueryRunner, TableColumn } from 'typeorm';

export class AddUserPreferences1234567890123 implements MigrationInterface {
    name = 'AddUserPreferences1234567890123';

    public async up(queryRunner: QueryRunner): Promise<void> {
        await queryRunner.addColumn('users', new TableColumn({
            name: 'preferences',
            type: 'jsonb',
            isNullable: true,
            default: "'{}'::jsonb"
        }));

        // Agregar √≠ndice GIN para b√∫squedas eficientes en JSONB
        await queryRunner.query(
            `CREATE INDEX "IDX_users_preferences" ON "users" USING gin ("preferences")`
        );
    }

    public async down(queryRunner: QueryRunner): Promise<void> {
        await queryRunner.query(`DROP INDEX "IDX_users_preferences"`);
        await queryRunner.dropColumn('users', 'preferences');
    }
}
```

**Generaci√≥n de migraciones:**

```bash
# Generar migraci√≥n autom√°ticamente
npm run migration:generate -- -n AddUserPreferences

# Crear migraci√≥n vac√≠a
npm run migration:create -- -n CustomMigration

# Ejecutar migraciones pendientes
npm run migration:run

# Revertir √∫ltima migraci√≥n
npm run migration:revert
```

**Configuraci√≥n:**

```typescript
// ormconfig.ts
export default {
  type: 'postgres',
  host: process.env.DB_HOST,
  port: parseInt(process.env.DB_PORT),
  username: process.env.DB_USERNAME,
  password: process.env.DB_PASSWORD,
  database: process.env.DB_DATABASE,
  entities: ['src/entities/*.ts'],
  migrations: ['src/migrations/*.ts'],
  cli: {
    migrationsDir: 'src/migrations',
  },
  synchronize: false, // NUNCA usar en producci√≥n
  migrationsRun: false, // Controlar manualmente
};
```

</Tab>
<Tab title="Prisma (Product Service)">

```sql
-- migrations/001_add_product_categories.sql
-- Add product categories table
CREATE TABLE product_categories (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    parent_id INTEGER REFERENCES product_categories(id),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Add category relationship to products
ALTER TABLE products 
ADD COLUMN category_id INTEGER REFERENCES product_categories(id);

-- Create indexes for performance
CREATE INDEX idx_products_category_id ON products(category_id);
CREATE INDEX idx_categories_parent_id ON product_categories(parent_id);
```

**Schema Prisma:**

```prisma
// schema.prisma
model ProductCategory {
  id          Int       @id @default(autoincrement())
  name        String    @db.VarChar(255)
  description String?   @db.Text
  parentId    Int?      @map("parent_id")
  parent      ProductCategory? @relation("CategoryHierarchy", fields: [parentId], references: [id])
  children    ProductCategory[] @relation("CategoryHierarchy")
  products    Product[]
  createdAt   DateTime  @default(now()) @map("created_at")
  updatedAt   DateTime  @updatedAt @map("updated_at")

  @@index([parentId])
  @@map("product_categories")
}

model Product {
  id         Int       @id @default(autoincrement())
  name       String
  categoryId Int?      @map("category_id")
  category   ProductCategory? @relation(fields: [categoryId], references: [id])
  
  @@index([categoryId])
  @@map("products")
}
```

**Comandos:**

```bash
# Generar migraci√≥n desde schema
npx prisma migrate dev --name add-product-categories

# Aplicar migraciones en producci√≥n
npx prisma migrate deploy

# Reset completo (solo desarrollo)
npx prisma migrate reset

# Ver estado de migraciones
npx prisma migrate status
```

</Tab>
<Tab title="Liquibase (Order Service)">

```xml
<!-- src/main/resources/db/changelog/001-create-orders-table.xml -->
<databaseChangeLog xmlns="http://www.liquibase.org/xml/ns/dbchangelog"
                   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                   xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog
                   http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-4.0.xsd">

    <changeSet id="1" author="developer">
        <createTable tableName="orders">
            <column name="id" type="BIGINT" autoIncrement="true">
                <constraints primaryKey="true" nullable="false"/>
            </column>
            <column name="user_id" type="BIGINT">
                <constraints nullable="false"/>
            </column>
            <column name="status" type="VARCHAR(50)">
                <constraints nullable="false"/>
            </column>
            <column name="total_amount" type="DECIMAL(10,2)">
                <constraints nullable="false"/>
            </column>
            <column name="created_at" type="TIMESTAMP" defaultValueComputed="CURRENT_TIMESTAMP">
                <constraints nullable="false"/>
            </column>
            <column name="updated_at" type="TIMESTAMP" defaultValueComputed="CURRENT_TIMESTAMP">
                <constraints nullable="false"/>
            </column>
        </createTable>

        <createIndex tableName="orders" indexName="idx_orders_user_id">
            <column name="user_id"/>
        </createIndex>

        <createIndex tableName="orders" indexName="idx_orders_status">
            <column name="status"/>
        </createIndex>
    </changeSet>

    <changeSet id="2" author="developer">
        <addColumn tableName="orders">
            <column name="payment_method" type="VARCHAR(50)" defaultValue="credit_card">
                <constraints nullable="false"/>
            </column>
        </addColumn>
    </changeSet>

</databaseChangeLog>
```

**Changelog maestro:**

```xml
<!-- src/main/resources/db/changelog/db.changelog-master.xml -->
<databaseChangeLog xmlns="http://www.liquibase.org/xml/ns/dbchangelog"
                   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                   xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog
                   http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-4.0.xsd">

    <include file="db/changelog/001-create-orders-table.xml"/>
    <include file="db/changelog/002-add-order-items-table.xml"/>
    <include file="db/changelog/003-add-payment-tracking.xml"/>

</databaseChangeLog>
```

**Comandos:**

```bash
# Aplicar migraciones
./mvnw liquibase:update

# Ver migraciones pendientes
./mvnw liquibase:status

# Generar rollback SQL
./mvnw liquibase:rollback-sql -Dliquibase.rollback-count=1

# Aplicar rollback
./mvnw liquibase:rollback -Dliquibase.rollback-count=1
```

</Tab>
</Tabs>

## Estrategias de Migraci√≥n Zero-Downtime

### 1. Migraciones Compatibles Hacia Atr√°s

<Callout type="info">
Dise√±a migraciones que mantengan compatibilidad con la versi√≥n anterior del c√≥digo durante el despliegue.
</Callout>

**Agregar Columnas (Seguro):**

```sql
-- ‚úÖ Buena pr√°ctica: columna opcional con valor por defecto
ALTER TABLE users 
ADD COLUMN email_verified BOOLEAN DEFAULT FALSE;

-- ‚úÖ √çndice concurrente (PostgreSQL)
CREATE INDEX CONCURRENTLY idx_users_email_verified 
ON users(email_verified);
```

**Eliminar Columnas (Proceso en 2 Fases):**

```sql
-- Fase 1: Marcar columna como deprecated (no eliminar)
-- Actualizar c√≥digo para no usar la columna

-- Fase 2: Eliminar despu√©s del despliegue
ALTER TABLE users DROP COLUMN deprecated_field;
```

### 2. Migraciones de Datos Grandes

Para tablas con millones de registros:

```sql
-- Migraci√≥n por lotes para evitar locks largos
DO $$
DECLARE
    batch_size INTEGER := 10000;
    affected_rows INTEGER;
BEGIN
    LOOP
        UPDATE users 
        SET status = 'active' 
        WHERE status IS NULL 
        AND id IN (
            SELECT id FROM users 
            WHERE status IS NULL 
            LIMIT batch_size
        );
        
        GET DIAGNOSTICS affected_rows = ROW_COUNT;
        
        -- Pausa entre lotes para reducir impacto
        PERFORM pg_sleep(0.1);
        
        EXIT WHEN affected_rows = 0;
    END LOOP;
END $$;
```

### 3. Renombrar Columnas/Tablas

**Estrategia de Vista Temporal:**

```sql
-- Paso 1: Crear nueva columna
ALTER TABLE users ADD COLUMN full_name VARCHAR(255);

-- Paso 2: Migrar datos
UPDATE users SET full_name = name WHERE full_name IS NULL;

-- Paso 3: Crear vista para compatibilidad
CREATE OR REPLACE VIEW users_legacy AS 
SELECT id, email, full_name as name, created_at 
FROM users;

-- Paso 4 (despu√©s del despliegue): Eliminar columna antigua
ALTER TABLE users DROP COLUMN name;
DROP VIEW users_legacy;
```

## Procedimientos de Testing

### Tests de Migraci√≥n

```typescript
// tests/migrations/migration.test.ts
describe('AddUserPreferences Migration', () => {
    let connection: Connection;

    beforeAll(async () => {
        connection = await createConnection({
            type: 'postgres',
            database: ':memory:',
            dropSchema: true,
            entities: [User],
            migrations: ['src/migrations/*.ts'],
            logging: false,
        });
    });

    it('should apply migration successfully', async () => {
        await connection.runMigrations();
        
        const queryRunner = connection.createQueryRunner();
        const table = await queryRunner.getTable('users');
        const preferencesColumn = table?.findColumnByName('preferences');
        
        expect(preferencesColumn).toBeDefined();
        expect(preferencesColumn?.type).toBe('jsonb');
    });

    it('should rollback migration successfully', async () => {
        await connection.undoLastMigration();
        
        const queryRunner = connection.createQueryRunner();
        const table = await queryRunner.getTable('users');
        const preferencesColumn = table?.findColumnByName('preferences');
        
        expect(preferencesColumn).toBeUndefined();
    });

    afterAll(async () => {
        await connection.close();
    });
});
```

### Validaci√≥n de Datos Post-Migraci√≥n

```typescript
// scripts/validate-migration.ts
import { Connection } from 'typeorm';

export async function validateMigration(connection: Connection): Promise<void> {
    // Verificar integridad referencial
    const orphanedRecords = await connection.query(`
        SELECT COUNT(*) as count 
        FROM orders o 
        LEFT JOIN users u ON o.user_id = u.id 
        WHERE u.id IS NULL
    `);
    
    if (orphanedRecords[0].count > 0) {
        throw new Error(`Found ${orphanedRecords[0].count} orphaned orders`);
    }

    // Verificar constraints
    const constraintViolations = await connection.query(`
        SELECT COUNT(*) as count 
        FROM users 
        WHERE email IS NULL OR email = ''
    `);
    
    if (constraintViolations[0].count > 0) {
        throw new Error('Email constraint violations detected');
    }

    console.log('Migration validation passed ‚úÖ');
}
```

## Automatizaci√≥n con CI/CD

### GitHub Actions

```yaml
# .github/workflows/database-migration.yml
name: Database Migration

on:
  push:
    branches: [main]
    paths: ['**/migrations/**']

jobs:
  test-migrations:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run migration tests
        run: npm run test:migrations
        env:
          DATABASE_URL: postgresql://postgres:test@localhost:5432/test

  deploy-staging:
    needs: test-migrations
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Deploy to staging
        run: |
          # Aplicar migraciones en staging
          kubectl exec -it staging-db -- \
            npm run migration:run
          
          # Ejecutar health checks
          npm run health-check:staging

  deploy-production:
    needs: deploy-staging
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - name: Backup production database
        run: |
          kubectl exec production-db -- \
            pg_dump -U postgres app_db > backup-$(date +%Y%m%d-%H%M%S).sql
            
      - name: Apply migrations to production
        run: |
          kubectl exec production-db -- \
            npm run migration:run
            
      - name: Validate migration
        run: |
          npm run validate:migration:production
```

## Rollback de Emergencia

### Script de Rollback Autom√°tico

```bash
#!/bin/bash
# scripts/emergency-rollback.sh

set -e

BACKUP_FILE=$1
DATABASE_URL=$2

if [ -z "$BACKUP_FILE" ] || [ -z "$DATABASE_URL" ]; then
    echo "Usage: $0 <backup_file> <database_url>"
    exit 1
fi

echo "üö® EMERGENCY ROLLBACK INITIATED"
echo "Backup file: $BACKUP_FILE"
echo "Database: $DATABASE_URL"

# Confirmaci√≥n requerida
read -p "Are you sure you want to rollback? This will restore from backup (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Rollback cancelled"
    exit 1
fi

# Crear backup actual antes del rollback
echo "Creating safety backup..."
pg_dump "$DATABASE_URL" > "emergency-backup-$(date +%Y%m%d-%H%M%S).sql"

# Restaurar desde backup
echo "Restoring from backup..."
psql "$DATABASE_URL" < "$BACKUP_FILE"

# Verificar estado
echo "Verifying rollback..."
npm run health-check

echo "‚úÖ Emergency rollback completed"
```

## Monitoreo y Alertas

### M√©tricas de Migraci√≥n

```typescript
// src/monitoring/migration-metrics.ts
import { Counter, Histogram, register } from 'prom-client';

export const migrationMetrics = {
    duration: new Histogram({
        name: 'db_migration_duration_seconds',
        help: 'Time taken to execute database migrations',
        labelNames: ['migration_name', 'status'],
    }),
    
    errors: new Counter({
        name: 'db_migration_errors_total',
        help: 'Total number of migration errors',
        labelNames: ['migration_name', 'error_type'],
    }),
};

register.registerMetric(migrationMetrics.duration);
register.registerMetric(migrationMetrics.errors);

export async function trackMigration<T>(
    migrationName: string,
    operation: () => Promise<T>
): Promise<T> {
    const startTime = Date.now();
    
    try {
        const result = await operation();
        
        migrationMetrics.duration
            .labels(migrationName, 'success')
            .observe((Date.now() - startTime) / 1000);
            
        return result;
    } catch (error) {
        migrationMetrics.duration
            .labels(migrationName, 'error')
            .observe((Date.now() - startTime) / 1000);
            
        migrationMetrics.errors
            .labels(migrationName, error.name)
            .inc();
            
        throw error;
    }
}
```

### Alertas Slack/Discord

```typescript
// src/notifications/migration-alerts.ts
import { WebhookClient } from 'discord.js';

const webhook = new WebhookClient({ 
    url: process.env.DISCORD_WEBHOOK_URL 
});

export async function notifyMigrationStatus(
    migrationName: string,
    status: 'started' | 'completed' | 'failed',
    details?: string
) {
    const emoji = {
        started: 'üîÑ',
        completed: '‚úÖ',
        failed: '‚ùå'
    };

    const color = {
        started: 0xFFFF00,
        completed: 0x00FF00,
        failed: 0xFF0000
    };

    await webhook.send({
        embeds: [{
            title: `${emoji[status]} Database Migration ${status.toUpperCase()}`,
            fields: [
                { name: 'Migration', value: migrationName, inline: true },
                { name: 'Environment', value: process.env.NODE_ENV, inline: true },
                { name: 'Timestamp', value: new Date().toISOString(), inline: true }
            ],
            description: details,
            color: color[status],
        }],
    });
}
```

## Best Practices

<Callout type="warning">
**Reglas de Oro para Migraciones Seguras:**

1. **Siempre crear backup** antes de aplicar en producci√≥n
2. **Probar en staging** con datos similares a producci√≥n
3. **Migraciones peque√±as** y at√≥micas
4. **Scripts idempotentes** que se puedan ejecutar m√∫ltiples veces
5. **Monitorear performance** durante y despu√©s de la migraci√≥n
</Callout>

### Checklist Pre-Producci√≥n

- [ ] Migraci√≥n probada en local
- [ ] Migraci√≥n probada en staging
- [ ] Backup de producci√≥n creado
- [ ] Scripts de rollback preparados
- [ ] Monitoreo configurado
- [ ] Ventana de mantenimiento programada (si necesaria)
- [ ] Equipo notificado del despliegue
- [ ] Plan de comunicaci√≥n con usuarios (si hay downtime)

### Naming Conventions

```bash
# Formato: YYYYMMDDHHMMSS-descriptive-name
20240315120000-add-user-preferences-column.sql
20240315130000-create-product-categories-table.sql
20240315140000-migrate-legacy-user-data.sql
```

Esta gu√≠a asegura que las migraciones se ejecuten de forma predecible y segura, minimizando riesgos en producci√≥n y manteniendo la integridad de los datos.