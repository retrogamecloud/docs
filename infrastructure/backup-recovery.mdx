---
title: Estrategia de Respaldo y Recuperación Ante Desastres
description: Documentación completa sobre backups, disaster recovery, RPO/RTO y procedimientos
  de restauración para RetroGameCloud
icon: shield-check
---

# Estrategia de Respaldo y Recuperación ante Desastres

<Note>
Esta documentación cubre la estrategia completa de backup y disaster recovery (DR) para la plataforma RetroGameCloud, incluyendo objetivos de recuperación, procedimientos automatizados y runbooks de emergencia.
</Note>

## Clasificación de Servicios por Criticidad

### Servicios Críticos
- **Authentication Service**: Sistema de autenticación y autorización
- **User Management**: Gestión de usuarios y perfiles
- **Kong Gateway**: API Gateway principal
- **Base de Datos Principal**: PostgreSQL con datos de usuarios

### Servicios Importantes
- **Game Scores**: Sistema de puntuaciones y rankings
- **Game Metadata**: Información de juegos y categorías
- **File Storage**: Almacenamiento de ROMs y saves
- **Notification Service**: Sistema de notificaciones

### Servicios Normales
- **Analytics**: Métricas y análisis de uso
- **Logging**: Agregación de logs
- **Monitoring**: Dashboards y alertas
- **Documentation**: Sitios de documentación

## Objetivos de Recuperación por Servicio

### RPO (Recovery Point Objective) y RTO (Recovery Time Objective)

<Tabs>
<Tab title="Servicios Críticos">

| Servicio | RPO | RTO | Justificación |
|----------|-----|-----|---------------|
| Authentication Service | 1 hora | 30 minutos | Impacto directo en acceso de usuarios |
| User Management | 1 hora | 30 minutos | Pérdida de datos críticos de usuario |
| Kong Gateway | 30 minutos | 15 minutos | Punto único de fallo para APIs |
| Base de Datos Principal | 1 hora | 30 minutos | Core de la aplicación |

</Tab>
<Tab title="Servicios Importantes">

| Servicio | RPO | RTO | Justificación |
|----------|-----|-----|---------------|
| Game Scores | 4 horas | 2 horas | Impacto en experiencia de usuario |
| Game Metadata | 12 horas | 4 horas | Funcionalidad degradada aceptable |
| File Storage (S3) | 24 horas | 2 horas | Redundancia nativa de S3 |
| Notification Service | 4 horas | 1 hora | Pérdida temporal aceptable |

</Tab>
<Tab title="Servicios Normales">

| Servicio | RPO | RTO | Justificación |
|----------|-----|-----|---------------|
| Analytics | 24 horas | 8 horas | No crítico para operación |
| Logging | 12 horas | 4 horas | Datos históricos disponibles |
| Monitoring | 1 hora | 2 horas | Crucial para detectar problemas |
| Documentation | 7 días | 24 horas | Contenido estático |

</Tab>
</Tabs>

## Estrategias de Backup Automatizado

### Base de Datos RDS PostgreSQL

<Tabs>
<Tab title="Configuración Terraform">

```hcl
resource "aws_db_instance" "retrogamecloud_db" {
  identifier = "retrogamecloud-prod"

  # Configuración de backups automatizados
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "sun:04:00-sun:05:00"

  # Snapshots finales
  final_snapshot_identifier = "retrogamecloud-final-snapshot"
  skip_final_snapshot      = false

  # Cifrado y alta disponibilidad
  storage_encrypted = true
  multi_az = true

  # Monitoreo mejorado
  monitoring_interval = 60
  monitoring_role_arn = aws_iam_role.rds_enhanced_monitoring.arn

  tags = {
    Environment = "production"
    Backup      = "automated"
  }
}

# Read Replica Cross-Region
resource "aws_db_instance" "retrogamecloud_replica" {
  identifier = "retrogamecloud-replica-us-west-2"
  
  replicate_source_db = aws_db_instance.retrogamecloud_db.identifier
  instance_class      = "db.t3.medium"
  
  # Cross-region configuration
  provider = aws.west

  tags = {
    Environment = "production"
    Purpose     = "disaster-recovery"
  }
}
```

</Tab>
<Tab title="Lambda Snapshot">

```python
import boto3
import json
from datetime import datetime

def lambda_handler(event, context):
    """
    Función Lambda para crear snapshots manuales programados
    """
    rds = boto3.client('rds')
    
    timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M')
    snapshot_id = f"retrogamecloud-manual-{timestamp}"
    
    try:
        response = rds.create_db_snapshot(
            DBSnapshotIdentifier=snapshot_id,
            DBInstanceIdentifier='retrogamecloud-prod',
            Tags=[
                {
                    'Key': 'Type',
                    'Value': 'Manual'
                },
                {
                    'Key': 'Environment',
                    'Value': 'production'
                }
            ]
        )
        
        # Cross-region copy
        rds_west = boto3.client('rds', region_name='us-west-2')
        rds_west.copy_db_snapshot(
            SourceDBSnapshotIdentifier=f"arn:aws:rds:us-east-1:account:snapshot:{snapshot_id}",
            TargetDBSnapshotIdentifier=f"{snapshot_id}-west"
        )
        
        return {
            'statusCode': 200,
            'body': json.dumps(f'Snapshot {snapshot_id} creado exitosamente')
        }
        
    except Exception as e:
        print(f"Error creando snapshot: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps(f'Error: {str(e)}')
        }
```

</Tab>
<Tab title="EventBridge Schedule">

```hcl
# Programación de snapshots manuales
resource "aws_cloudwatch_event_rule" "db_snapshot_schedule" {
  name        = "retrogamecloud-snapshot-schedule"
  description = "Trigger manual DB snapshots"
  
  # Cada 6 horas
  schedule_expression = "rate(6 hours)"
  
  tags = {
    Environment = "production"
  }
}

resource "aws_cloudwatch_event_target" "lambda_target" {
  rule      = aws_cloudwatch_event_rule.db_snapshot_schedule.name
  target_id = "TriggerLambdaSnapshot"
  arn       = aws_lambda_function.db_snapshot.arn
}

resource "aws_lambda_permission" "allow_eventbridge" {
  statement_id  = "AllowExecutionFromEventBridge"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.db_snapshot.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.db_snapshot_schedule.arn
}
```

</Tab>
</Tabs>

### Backup de Configuraciones Kubernetes

```yaml
# velero-backup-schedule.yaml
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: retrogamecloud-daily-backup
  namespace: velero
spec:
  schedule: "0 2 * * *"  # 2 AM diario
  template:
    includedNamespaces:
    - retrogamecloud-prod
    - kong
    - monitoring
    excludedResources:
    - events
    - events.events.k8s.io
    storageLocation: aws-backup-storage
    ttl: 168h0m0s  # 7 días

---
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: retrogamecloud-weekly-backup
  namespace: velero
spec:
  schedule: "0 1 * * 0"  # Domingos 1 AM
  template:
    includeClusterResources: true
    storageLocation: aws-backup-storage
    ttl: 720h0m0s  # 30 días
```

### Backup de Archivos S3

```hcl
# Replicación cross-region S3
resource "aws_s3_bucket_replication_configuration" "retrogamecloud_replication" {
  role   = aws_iam_role.replication.arn
  bucket = aws_s3_bucket.retrogamecloud_games.id

  rule {
    id     = "ReplicateToWest"
    status = "Enabled"

    destination {
      bucket        = aws_s3_bucket.retrogamecloud_games_backup.arn
      storage_class = "STANDARD_IA"
      
      # Cifrado en destino
      encryption_configuration {
        replica_kms_key_id = aws_kms_key.s3_backup_key.arn
      }
    }
  }
}

# Lifecycle para backups S3
resource "aws_s3_bucket_lifecycle_configuration" "backup_lifecycle" {
  bucket = aws_s3_bucket.retrogamecloud_games_backup.id

  rule {
    id     = "backup_lifecycle"
    status = "Enabled"

    transition {
      days          = 30
      storage_class = "GLACIER"
    }

    transition {
      days          = 90
      storage_class = "DEEP_ARCHIVE"
    }

    expiration {
      days = 2555  # 7 años
    }
  }
}
```

## Runbooks de Recovery por Escenario

### Escenario 1: Fallo de Región AWS Principal

<Steps>
<Step title="Detección y Evaluación">

```bash
#!/bin/bash
# check-region-health.sh

echo "Verificando salud de región us-east-1..."

# Check RDS availability
aws rds describe-db-instances \
  --db-instance-identifier retrogamecloud-prod \
  --region us-east-1 \
  --query 'DBInstances[0].DBInstanceStatus'

# Check EKS cluster
aws eks describe-cluster \
  --name retrogamecloud-prod \
  --region us-east-1 \
  --query 'cluster.status'

# Check S3 bucket accessibility
aws s3 ls s3://retrogamecloud-games-prod/ --region us-east-1

echo "Evaluación completada. Revisa los resultados arriba."
```

</Step>
<Step title="Activación de Región Secundaria">

```bash
#!/bin/bash
# activate-dr-region.sh

set -e

echo "Iniciando activación de región DR (us-west-2)..."

# 1. Promover Read Replica a Master
aws rds promote-read-replica \
  --db-instance-identifier retrogamecloud-replica-us-west-2 \
  --region us-west-2

# 2. Actualizar Route53 para failover
aws route53 change-resource-record-sets \
  --hosted-zone-id Z1234567890 \
  --change-batch file://failover-changeset.json

# 3. Desplegar aplicaciones en región DR
kubectl config use-context eks-west-2
kubectl apply -f k8s/production/ -n retrogamecloud-prod

echo "Región DR activada. Verificando servicios..."
```

</Step>
<Step title="Validación de Servicios">

```bash
#!/bin/bash
# validate-dr-services.sh

echo "Validando servicios en región DR..."

# Check database connectivity
pg_isready -h retrogamecloud-replica-us-west-2.region.rds.amazonaws.com -p 5432

# Check API Gateway
curl -f https://api-dr.retrogamecloud.com/health

# Check application pods
kubectl get pods -n retrogamecloud-prod -o wide

# Run smoke tests
npm run test:smoke:production

echo "Validación completada."
```

</Step>
</Steps>

### Escenario 2: Corrupción de Base de Datos

<Tabs>
<Tab title="Detección">

```sql
-- queries-validation.sql
-- Consultas para detectar corrupción de datos

-- Verificar integridad referencial
SELECT conname, conrelid::regclass 
FROM pg_constraint 
WHERE NOT EXISTS (
  SELECT 1 FROM pg_trigger 
  WHERE tgconstraint = pg_constraint.oid
);

-- Verificar tablas con registros inconsistentes
SELECT schemaname, tablename, n_dead_tup, n_live_tup
FROM pg_stat_user_tables 
WHERE n_dead_tup > n_live_tup * 0.1;

-- Verificar índices corruptos
SELECT schemaname, tablename, indexname, idx_blks_hit, idx_blks_read
FROM pg_statio_user_indexes 
WHERE idx_blks_read > 0 AND idx_blks_hit = 0;
```

</Step>
<Tab title="Recovery Procedure">

```bash
#!/bin/bash
# db-corruption-recovery.sh

set -e

SNAPSHOT_ID="retrogamecloud-manual-$(date +%Y-%m-%d)"
NEW_DB_INSTANCE="retrogamecloud-recovery-$(date +%s)"

echo "Iniciando recovery por corrupción de BD..."

# 1. Crear snapshot de emergencia de DB actual
aws rds create-db-snapshot \
  --db-instance-identifier retrogamecloud-prod \
  --db-snapshot-identifier "${SNAPSHOT_ID}-corruption-backup"

# 2. Encontrar último snapshot válido
LAST_SNAPSHOT=$(aws rds describe-db-snapshots \
  --db-instance-identifier retrogamecloud-prod \
  --snapshot-type automated \
  --query 'DBSnapshots[0].DBSnapshotIdentifier' \
  --output text)

# 3. Restaurar desde snapshot válido
aws rds restore-db-instance-from-db-snapshot \
  --db-instance-identifier $NEW_DB_INSTANCE \
  --db-snapshot-identifier $LAST_SNAPSHOT \
  --db-instance-class db.r5.xlarge \
  --multi-az

# 4. Esperar que la nueva instancia esté disponible
aws rds wait db-instance-available \
  --db-instance-identifier $NEW_DB_INSTANCE

echo "Recovery completado. Nueva instancia: $NEW_DB_INSTANCE"
```

</Tab>
<Tab title="Data Validation">

```python
# validate-recovered-data.py
import psycopg2
import sys
from datetime import datetime, timedelta

def validate_data_integrity(connection_string):
    """Valida la integridad de los datos recuperados"""
    
    conn = psycopg2.connect(connection_string)
    cursor = conn.cursor()
    
    validations = []
    
    # Validar conteos de tablas principales
    tables_to_check = ['users', 'games', 'scores', 'user_sessions']
    
    for table in tables_to_check:
        cursor.execute(f"SELECT COUNT(*) FROM {table}")
        count = cursor.fetchone()[0]
        validations.append(f"{table}: {count} registros")
    
    # Validar datos recientes (últimas 24h antes del snapshot)
    cursor.execute("""
        SELECT COUNT(*) FROM scores 
        WHERE created_at > %s
    """, (datetime.now() - timedelta(days=
</Tab>
</Tab>
</Tabs>
```