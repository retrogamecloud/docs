---
title: 6.10. Optimizaci√≥n de Costos AWS
description: Gu√≠a completa para monitorizar y optimizar los costos operativos de RetroGameCloud
  en AWS
icon: coins
---

# 6.10. Optimizaci√≥n de Costos AWS

Esta gu√≠a proporciona estrategias espec√≠ficas para optimizar los costos de infraestructura de RetroGameCloud, incluyendo an√°lisis detallado de gastos por servicio y recomendaciones de ahorro.

## An√°lisis de Costos por Servicio

### Breakdown de Costos Actual

<Tabs>
<Tab title="EKS y Compute">

* *Amazon EKS Cluster**

- Control Plane: $73/mes por cluster

- Worker Nodes (3x t3.medium): ~$65/mes

- Load Balancer: ~$18/mes

- **Total EKS**: ~$156/mes

* *Potencial de Ahorro**: 40-70% con Reserved/Spot Instances
</Tab>
<Tab title="RDS PostgreSQL">

* *Base de Datos**

- RDS PostgreSQL (db.t3.micro): ~$13/mes

- Multi-AZ: +100% (~$26/mes total)

- Snapshots automatizados: ~$5/mes

- **Total RDS**: ~$31/mes

* *Potencial de Ahorro**: 38% con Reserved Instances
</Tab>
<Tab title="Almacenamiento y CDN">

* *Amazon S3**

- Almacenamiento Standard: ~$23/TB/mes

- ROMs y assets de juegos: estimado 50GB (~$1.15/mes)

- Transferencia de datos: ~$0.09/GB

* *CloudFront CDN**

- Primeros 1TB gratis/mes

- Costos adicionales: $0.085/GB

- **Total estimado**: ~$15-30/mes seg√∫n tr√°fico
</Tab>
</Tabs>

### Herramientas de Monitorizaci√≥n

```yaml

# AWS Cost Explorer Query Example
cost_analysis:
  services:
    - service: "Amazon Elastic Kubernetes Service"
      monthly_cost: "$156"
      optimization_potential: "40-70%"
    - service: "Amazon RDS"
      monthly_cost: "$31"
      optimization_potential: "38%"
    - service: "Amazon S3"
      monthly_cost: "$15"
      optimization_potential: "60% (Intelligent Tiering)"

```

## Estrategias de Optimizaci√≥n

### Reserved Instances para EKS

<Note>
Las Reserved Instances pueden reducir los costos de compute hasta un 40% comparado con instancias On-Demand.
</Note>

* *Implementaci√≥n para Worker Nodes:**

```bash

# An√°lisis de uso actual
aws ce get-usage-and-costs \
  --time-period Start=2024-01-01,End=2024-02-01 \
  --granularity MONTHLY \
  --metrics BlendedCost \
  --group-by Type=DIMENSION,Key=INSTANCE_TYPE

# Compra de Reserved Instance recomendada
aws ec2 purchase-reserved-instances-offering \
  --reserved-instances-offering-id <offering-id> \
  --instance-count 3

```

* *Configuraci√≥n Terraform para RI:**

```hcl

# terraform/reserved-instances.tf
resource "aws_ec2_reserved_instance" "eks_workers" {
  availability_zone    = "eu-west-1a"
  duration            = 31536000  # 1 a√±o
  fixed_price         = 227       # Precio por t3.medium
  instance_count      = 3
  instance_type       = "t3.medium"
  product_description = "Linux/UNIX"
  reserved_instances_offering_id = data.aws_ec2_reserved_instance_offering.example.id
}

```

### Spot Instances para Cargas No Cr√≠ticas

<Warning>
Utiliza Spot Instances solo para workloads que toleran interrupciones, como procesamiento de m√©tricas o tareas de backup.
</Warning>

* *Configuraci√≥n de Spot Node Group:**

```yaml

# k8s/spot-nodegroup.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spot-nodegroup-config
data:
  nodegroup.yaml: |
    apiVersion: eksctl.io/v1alpha5
    kind: ClusterConfig
    metadata:
      name: retrogame-cluster
      region: eu-west-1

    nodeGroups:
    - name: spot-workers
      instanceTypes:
        - t3.medium
        - t3.large
      spot: true
      minSize: 1
      maxSize: 5
      desiredCapacity: 2
      labels:
        node-type: "spot"
      taints:
        spot: "true:NoSchedule"

```

* *Tolerations para Pods Compatibles:**

```yaml

# k8s/deployments/metrics-processor.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-processor
spec:
  replicas: 2
  selector:
    matchLabels:
      app: metrics-processor
  template:
    spec:
      tolerations:
      - key: "spot"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"
      nodeSelector:
        node-type: "spot"
      containers:
      - name: processor
        image: retrogame/metrics-processor:latest
        resources:
          requests:
            cpu: 100m
            memory: 128Mi

```

### S3 Intelligent Tiering y Lifecycle Policies

* *Pol√≠tica de Ciclo de Vida para Backups:**

```json
{
  "Rules": [
    {
      "ID": "RetroGameBackupLifecycle",
      "Status": "Enabled",
      "Filter": {
        "Prefix": "backups/"
      },
      "Transitions": [
        {
          "Days": 30,
          "StorageClass": "STANDARD_IA"
        },
        {
          "Days": 90,
          "StorageClass": "GLACIER"
        },
        {
          "Days": 365,
          "StorageClass": "DEEP_ARCHIVE"
        }
      ],
      "Expiration": {
        "Days": 2555
      }
    }
  ]
}

```

* *Terraform para S3 Optimization:**

```hcl
resource "aws_s3_bucket_lifecycle_configuration" "retrogame_lifecycle" {
  bucket = aws_s3_bucket.retrogame_storage.id

  rule {
    id     = "game_assets_optimization"
    status = "Enabled"

    filter {
      prefix = "roms/"
    }

    transition {
      days          = 30
      storage_class = "STANDARD_INFREQUENT_ACCESS"
    }

    transition {
      days          = 90
      storage_class = "GLACIER_INSTANT_RETRIEVAL"
    }
  }

  rule {
    id     = "logs_cleanup"
    status = "Enabled"

    filter {
      prefix = "logs/"
    }

    expiration {
      days = 90
    }
  }
}

resource "aws_s3_bucket_intelligent_tiering_configuration" "retrogame_tiering" {
  bucket = aws_s3_bucket.retrogame_storage.id
  name   = "EntireBucket"

  status = "Enabled"

  tiering {
    access_tier = "ARCHIVE_ACCESS"
    days        = 90
  }

  tiering {
    access_tier = "DEEP_ARCHIVE_ACCESS"
    days        = 180
  }
}

```

## AWS Cost Anomaly Detection

### Configuraci√≥n de Alertas

```hcl

# terraform/cost-anomaly-detection.tf
resource "aws_ce_anomaly_detector" "retrogame_detector" {
  name         = "retrogame-cost-anomaly"
  monitor_type = "DIMENSIONAL"

  specification = jsonencode({
    Dimension     = "SERVICE"
    MatchOptions  = ["EQUALS"]
    Values        = ["Amazon Elastic Kubernetes Service", "Amazon RDS"]
    CostCategories = {}
    Tags = {}
  })
}

resource "aws_ce_anomaly_subscription" "retrogame_subscription" {
  name      = "retrogame-anomaly-alerts"
  frequency = "DAILY"

  monitor_arn_list = [
    aws_ce_anomaly_detector.retrogame_detector.arn
  ]

  subscriber {
    type    = "EMAIL"
    address = "devops@retrogamecloud.com"
  }

  threshold_expression {
    and {
      dimension {
        key           = "ANOMALY_TOTAL_IMPACT_ABSOLUTE"
        values        = ["100"]
        match_options = ["GREATER_THAN_OR_EQUAL"]
      }
    }
  }
}

```

### Dashboard de Costos

```yaml

# monitoring/cost-dashboard.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cost-dashboard-config
data:
  dashboard.json: |
    {
      "dashboard": {
        "title": "RetroGameCloud - Cost Optimization",
        "panels": [
          {
            "title": "Monthly Cost by Service",
            "type": "piechart",
            "targets": [
              {
                "expr": "aws_billing_estimated_charges",
                "legendFormat": "{{service_name}}"
              }
            ]
          },
          {
            "title": "EKS Nodes Utilization vs Cost",
            "type": "graph",
            "targets": [
              {
                "expr": "100 - (avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
                "legendFormat": "CPU Utilization %"
              }
            ]
          }
        ]
      }
    }

```

## Rightsizing de Instancias

### An√°lisis de M√©tricas Actuales

<Tabs>
<Tab title="Comando de An√°lisis">

```bash
#!/bin/bash

# scripts/analyze-instance-utilization.sh

echo "=== An√°lisis de Utilizaci√≥n de Instancias EKS ==="

# CPU promedio por nodo en los √∫ltimos 7 d√≠as
kubectl top nodes

# M√©tricas detalladas de Prometheus
curl -G 'http://prometheus:9090/api/v1/query' \
  --data-urlencode 'query=avg_over_time(100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)[7d:1h])' | \
  jq -r '.data.result[] | "Node: \(.metric.instance) - CPU Avg: \(.value[1])%"'

# Memoria promedio
curl -G 'http://prometheus:9090/api/v1/query' \
  --data-urlencode 'query=avg_over_time((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100[7d:1h])' | \
  jq -r '.data.result[] | "Node: \(.metric.instance) - Memory Avg: \(.value[1])%"'

echo "=== Recomendaciones de Rightsizing ==="
if [[ $(echo "$cpu_avg < 20" | bc) -eq 1 ]]; then
  echo "‚ö†Ô∏è  CPU utilization < 20% - Consider t3.small instead of t3.medium"
fi

```

</Tab>
<Tab title="Configuraci√≥n Optimizada">

```yaml

# k8s/optimized-nodegroup.yaml
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: retrogame-cluster
  region: eu-west-1

nodeGroups:

- name: optimized-workers
  # Cambio de t3.medium a t3.small basado en m√©tricas
  instanceTypes: ["t3.small"]
  minSize: 2
  maxSize: 6
  desiredCapacity: 3

  # Configurar instance metadata
  instanceMetadata:
    httpPutResponseHopLimit: 2
    httpTokens: required

  # Tags para cost tracking
  tags:
    Environment: "production"
    CostCenter: "retrogame-ops"
    Rightsized: "true"

  # Resource limits m√°s precisos
  kubeletExtraConfig:
    maxPods: 20  # Reducido de 110 default

```

</Tab>
</Tabs>

### Automatizaci√≥n de Rightsizing

```python

# scripts/auto-rightsizing.py
import boto3
import json
from datetime import datetime, timedelta

class EKSRightsizing:
    def __init__(self):
        self.cloudwatch = boto3.client('cloudwatch')
        self.eks = boto3.client('eks')
        self.ec2 = boto3.client('ec2')

    def get_node_utilization(self, instance_id, days=7):
        """Obtiene m√©tricas de utilizaci√≥n de los √∫ltimos N d√≠as"""
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=days)

        # CPU Utilization
        cpu_response = self.cloudwatch.get_metric_statistics(
            Namespace='AWS/EC2',
            MetricName='CPUUtilization',
            Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],
            StartTime=start_time,
            EndTime=end_time,
            Period=3600,  # 1 hour
            Statistics=['Average']
        )

        cpu_avg = sum(point['Average'] for point in cpu_response['Datapoints']) / len(cpu_response['Datapoints'])

        return {
            'instance_id': instance_id,
            'cpu_average': cpu_avg,
            'memory_average': self._get_memory_utilization(instance_id, start_time, end_time)
        }

    def recommend_instance_type(self, current_type, cpu_avg, memory_avg):
        """Recomienda tipo de instancia basado en utilizaci√≥n"""
        recommendations = {
            't3.medium': {
                'downsize_to': 't3.small',
                'cpu_threshold': 30,
                'memory_threshold': 40
            },
            't3.large': {
                'downsize_to': 't3.medium',
                'cpu_threshold': 40,
                'memory_threshold': 50
            }
        }

        if current_type in recommendations:
            thresholds = recommendations[current_type]
            if cpu_avg < thresholds['cpu_threshold'] and memory_avg < thresholds['memory_threshold']:
                return {
                    'recommended_type': thresholds['downsize_to'],
                    'potential_savings': self._calculate_savings(current_type, thresholds['downsize_to'])
                }

        return {'recommended_type': current_type, 'potential_savings': 0}

if __name__ == "__main__":
    rightsizer = EKSRightsizing()
    # Analizar y generar recomendaciones
    recommendations = rightsizer.analyze_cluster_nodes('retrogame-cluster')
    print(json.dumps(recommendations, indent=2))

```

## Limpieza de Recursos Hu√©rfanos

### Script de Detecci√≥n y Limpieza

```bash
#!/bin/bash

# scripts/cleanup-orphaned-resources.sh

echo "üîç Buscando recursos hu√©rfanos en AWS..."

# 1. EBS Volumes no attachados
echo "=== EBS Volumes no attachados ==="
aws ec2 describe-volumes \
  --filters Name=status,Values=available \
  --query 'Volumes[?State==`available`].[VolumeId,Size,CreateTime]' \
  --output table

```