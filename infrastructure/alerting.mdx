---
title: "Monitorización y Observabilidad"
description: "Stack completo de observabilidad para RetroGameCloud: métricas, logs, alertas y dashboards"
icon: "chart-line"
---

# Monitorización y Observabilidad

RetroGameCloud implementa un stack completo de observabilidad que combina herramientas nativas de AWS con soluciones open source para garantizar la visibilidad total del sistema en producción.

## Stack de Observabilidad

<Card title="Componentes Principales" icon="stack">
- **CloudWatch Logs**: Agregación centralizada de logs
- **CloudWatch Metrics**: Métricas de infraestructura AWS
- **Prometheus**: Recolección de métricas de aplicación
- **Grafana**: Dashboards y visualización
- **CloudWatch Alarms**: Sistema de alertas
- **AWS X-Ray**: Trazado distribuido
</Card>

## Métricas de Negocio por Servicio

### Auth Service

<Tabs>
<Tab title="Métricas Clave">
```yaml
# Métricas críticas del servicio de autenticación
auth_registrations_total:
  description: "Total de registros de usuarios"
  type: "counter"
  labels: ["status", "provider"]

auth_login_attempts_total:
  description: "Intentos de login"
  type: "counter"
  labels: ["status", "method"]

auth_token_validation_duration:
  description: "Duración de validación de tokens"
  type: "histogram"
  buckets: [0.1, 0.5, 1.0, 2.0, 5.0]

auth_active_sessions:
  description: "Sesiones activas concurrentes"
  type: "gauge"
```
</Tab>
<Tab title="Umbrales de Alerta">
- **Tasa de fallos de login > 15%**: Posible ataque de fuerza bruta
- **Duración de validación p95 > 500ms**: Degradación del rendimiento
- **Registros/hora < 10**: Posible problema en el flujo de registro
- **Sesiones activas > 10000**: Revisar capacidad del sistema
</Tab>
</Tabs>

### Game Catalog Service

```yaml
# Métricas del catálogo de juegos
game_catalog_searches_total:
  description: "Búsquedas realizadas en el catálogo"
  type: "counter"
  labels: ["category", "platform"]

game_downloads_total:
  description: "Descargas de ROMs"
  type: "counter"
  labels: ["game_id", "platform"]

game_catalog_response_time:
  description: "Tiempo de respuesta del catálogo"
  type: "histogram"
  buckets: [0.1, 0.2, 0.5, 1.0, 2.0]

most_played_games:
  description: "Juegos más jugados (top 10)"
  type: "gauge"
  labels: ["game_name", "platform"]
```

<Warning>
El servicio de catálogo debe mantener un tiempo de respuesta p95 inferior a 1 segundo para garantizar una buena experiencia de usuario.
</Warning>

### Score y Ranking Services

<Tabs>
<Tab title="Score Service">
```yaml
score_submissions_total:
  description: "Puntuaciones enviadas"
  type: "counter"
  labels: ["game_id", "user_type"]

score_validation_failures:
  description: "Fallos en validación de puntuaciones"
  type: "counter"
  labels: ["reason", "game_id"]

score_processing_duration:
  description: "Tiempo de procesamiento de puntuaciones"
  type: "histogram"
```
</Tab>
<Tab title="Ranking Service">
```yaml
ranking_updates_total:
  description: "Actualizaciones de ranking"
  type: "counter"
  labels: ["ranking_type", "game_id"]

ranking_calculation_duration:
  description: "Duración del cálculo de rankings"
  type: "histogram"

leaderboard_requests_total:
  description: "Solicitudes de leaderboard"
  type: "counter"
  labels: ["game_id", "period"]
```
</Tab>
</Tabs>

## Métricas de Infraestructura

### Cluster EKS

<Card title="Métricas de Nodos" icon="server">
```yaml
# Métricas críticas de infraestructura
node_cpu_utilization:
  description: "Uso de CPU por nodo"
  threshold_warning: 70%
  threshold_critical: 85%

node_memory_utilization:
  description: "Uso de memoria por nodo"
  threshold_warning: 80%
  threshold_critical: 90%

node_disk_utilization:
  description: "Uso de disco por nodo"
  threshold_warning: 75%
  threshold_critical: 85%

pod_restart_count:
  description: "Reinicios de pods"
  threshold_warning: 3_restarts_per_hour
  threshold_critical: 5_restarts_per_hour
```
</Card>

### Pods y Contenedores

```yaml
# Métricas por servicio
container_cpu_usage:
  labels: ["service", "pod", "namespace"]
  
container_memory_usage:
  labels: ["service", "pod", "namespace"]

container_network_receive_bytes:
  description: "Bytes recibidos por contenedor"
  
container_network_transmit_bytes:
  description: "Bytes transmitidos por contenedor"

# Umbrales por servicio
service_thresholds:
  auth-service:
    cpu_warning: 200m
    cpu_critical: 400m
    memory_warning: 256Mi
    memory_critical: 512Mi
  
  game-catalog:
    cpu_warning: 300m
    cpu_critical: 500m
    memory_warning: 512Mi
    memory_critical: 1Gi
```

## Base de Datos (PostgreSQL en RDS)

<Warning>
Las métricas de base de datos son críticas para el rendimiento del sistema. Monitoriza especialmente las conexiones activas y la latencia de consultas.
</Warning>

```yaml
# Métricas de RDS PostgreSQL
rds_database_connections:
  description: "Conexiones activas a la base de datos"
  threshold_warning: 80  # 80% del máximo configurado
  threshold_critical: 90  # 90% del máximo configurado

rds_cpu_utilization:
  threshold_warning: 70%
  threshold_critical: 85%

rds_free_memory:
  threshold_warning: 1GB
  threshold_critical: 500MB

rds_read_latency:
  threshold_warning: 200ms
  threshold_critical: 500ms

rds_write_latency:
  threshold_warning: 200ms
  threshold_critical: 500ms
```

## CloudWatch Alarms Críticos

### Configuración de Alertas

<Tabs>
<Tab title="Infraestructura">
```json
{
  "critical_alarms": [
    {
      "name": "EKS-Cluster-UnhealthyNodes",
      "metric": "cluster.unhealthy_nodes",
      "threshold": 1,
      "comparison": "GreaterThanOrEqualToThreshold",
      "evaluation_periods": 2,
      "period": 300,
      "notification": "sns:retrogame-critical-alerts"
    },
    {
      "name": "RDS-ConnectionsHigh",
      "metric": "DatabaseConnections",
      "threshold": 80,
      "comparison": "GreaterThanThreshold",
      "evaluation_periods": 3,
      "period": 300,
      "notification": "sns:retrogame-critical-alerts"
    },
    {
      "name": "ALB-5xxErrorsHigh",
      "metric": "HTTPCode_Target_5XX_Count",
      "threshold": 10,
      "comparison": "GreaterThanThreshold",
      "evaluation_periods": 2,
      "period": 300,
      "notification": "sns:retrogame-critical-alerts"
    }
  ]
}
```
</Tab>
<Tab title="Aplicación">
```json
{
  "application_alarms": [
    {
      "name": "Auth-Service-ErrorRate",
      "metric": "auth_errors_total",
      "threshold": 0.05,  // 5% de tasa de error
      "comparison": "GreaterThanThreshold",
      "evaluation_periods": 3,
      "period": 300
    },
    {
      "name": "Game-Download-Failures",
      "metric": "game_download_failures_total",
      "threshold": 20,
      "comparison": "GreaterThanThreshold",
      "evaluation_periods": 2,
      "period": 600
    },
    {
      "name": "Score-Processing-Latency",
      "metric": "score_processing_duration_p95",
      "threshold": 2.0,  // 2 segundos
      "comparison": "GreaterThanThreshold",
      "evaluation_periods": 3,
      "period": 300
    }
  ]
}
```
</Tab>
</Tabs>

## Logs Centralizados

### Configuración de CloudWatch Logs

```yaml
# Configuración de log groups
log_groups:
  - name: "/aws/eks/retrogame-cluster/cluster"
    retention_days: 7
    
  - name: "/retrogame/auth-service"
    retention_days: 30
    
  - name: "/retrogame/game-catalog"
    retention_days: 30
    
  - name: "/retrogame/score-service"
    retention_days: 14
    
  - name: "/retrogame/ranking-service"
    retention_days: 14
    
  - name: "/retrogame/nginx-ingress"
    retention_days: 14

# Configuración de Fluent Bit
fluent_bit_config: |
  [INPUT]
      Name              tail
      Path              /var/log/containers/*.log
      Parser            docker
      Tag               kube.*
      Refresh_Interval  5
      
  [FILTER]
      Name                kubernetes
      Match               kube.*
      Kube_URL            https://kubernetes.default.svc:443
      Merge_Log           On
      Keep_Log            Off
      
  [OUTPUT]
      Name                cloudwatch_logs
      Match               kube.*
      region              eu-west-1
      log_group_name      /aws/eks/retrogame-cluster/application
      auto_create_group   true
```

### Acceso a Logs con kubectl

<Note>
Para acceder a los logs de los servicios en tiempo real, utiliza estos comandos de kubectl:
</Note>

```bash
# Ver logs de un servicio específico
kubectl logs -f deployment/auth-service -n retrogame

# Ver logs de múltiples pods
kubectl logs -f -l app=game-catalog -n retrogame

# Ver logs con contexto de tiempo
kubectl logs --since=1h deployment/score-service -n retrogame

# Ver logs de un pod específico con múltiples contenedores
kubectl logs -f pod/auth-service-7d4b6c8f9-xk2m9 -c auth-service -n retrogame

# Filtrar logs por nivel (si está estructurado)
kubectl logs deployment/ranking-service -n retrogame | grep ERROR

# Ver eventos del cluster
kubectl get events --sort-by='.lastTimestamp' -n retrogame
```

## CloudWatch Insights

### Queries Útiles

<Tabs>
<Tab title="Análisis de Errores">
```sql
# Errores por servicio en las últimas 24 horas
fields @timestamp, @message
| filter @message like /ERROR/
| stats count() by bin(5m)
| sort @timestamp desc

# Top 10 errores más frecuentes
fields @timestamp, @message
| filter @message like /ERROR/
| parse @message /ERROR: (?<error_message>.*)/
| stats count() as error_count by error_message
| sort error_count desc
| limit 10
```
</Tab>
<Tab title="Rendimiento">
```sql
# Análisis de latencia por endpoint
fields @timestamp, @message
| filter @message like /request_duration/
| parse @message /duration=(?<duration>\d+)/
| stats avg(duration), max(duration), min(duration) by bin(5m)
| sort @timestamp desc

# Requests por minuto
fields @timestamp
| filter @message like /HTTP/
| stats count() as requests by bin(1m)
| sort @timestamp desc
```
</Tab>
<Tab title="Usuarios y Juegos">
```sql
# Juegos más jugados
fields @timestamp, @message
| filter @message like /game_started/
| parse @message /game_id=(?<game_id>\w+)/
| stats count() as plays by game_id
| sort plays desc
| limit 20

# Actividad de usuarios por hora
fields @timestamp, @message
| filter @message like /user_login/
| stats count() as logins by bin(1h)
| sort @timestamp desc
```
</Tab>
</Tabs>

## Dashboards de Grafana

### Dashboard Principal del Sistema

```json
{
  "dashboard": {
    "title": "RetroGameCloud - Vista General",
    "panels": [
      {
        "title": "Solicitudes por Segundo",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m])) by (service)",
            "legendFormat": "{{service}}"
          }
        ]
      },
      {
        "title": "Latencia p95 por Servicio",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service))",
            "legendFormat": "p95 {{service}}"
          }
        ]
      },
      {
        "title": "Tasa de Error",
        "type": "singlestat",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m]))",
            "legendFormat": "Error Rate"
          }
        ]
      }
    ]
  }
}
```

### Dashboard de Infraestructura

<Card title="Métricas de Infraestructura" icon="chart-bar">
- **Uso de CPU y Memoria por nodo**
- **Tráfico de red del cluster**
- **Almacenamiento disponible**
- **Estado de los pods**
- **Métricas de RDS**
- **Distribución de tráfico del Load Balancer**
</Card>

## Procedimientos de Respuesta a Incidentes

### Runbook de Alertas

<Warning>
Sigue estos procedimientos cuando recibas alertas críticas:
</Warning>

<Tabs>
<Tab title="Alta Tasa de Error 5xx">
```bash
# 1. Verificar estado de los pods
kubectl get pods -n retrogame

# 2. Revisar logs recientes
kubectl logs -f deployment/auth-service -n retrogame --tail=100

# 3. Verificar métricas de recursos
kubectl top pods -n retrogame

# 4. Comprobar conectividad con RDS
kubectl exec -it deployment/auth-service -n retrogame -- pg_isready -h $DB_HOST

# 5. Si es necesario, hacer rollback
kubectl rollout undo deployment/auth-service -n retrogame
```
</Tab>
<Tab title="Nodos Unhealthy">
```bash
# 1. Verificar estado del cluster
kubectl