#!/usr/bin/env python3
"""
Intelligent Documentation Analyzer with Claude AI
Analiza toda la documentaci√≥n y arquitectura del proyecto para proponer mejoras
"""
import os
import sys
import json
import argparse
import anthropic
from pathlib import Path
from datetime import datetime
from json_repair import repair_json

def scan_directory_structure(base_path):
    """Escanea la estructura completa del directorio"""
    structure = {"files": [], "dirs": []}
    
    for root, dirs, files in os.walk(base_path):
        # Ignorar directorios ocultos y node_modules
        dirs[:] = [d for d in dirs if not d.startswith('.') and d != 'node_modules']
        
        rel_root = os.path.relpath(root, base_path)
        if rel_root != '.':
            structure["dirs"].append(rel_root)
        
        for file in files:
            if file.endswith(('.md', '.mdx', '.js', '.py', '.tf', '.yml', '.yaml')):
                structure["files"].append(os.path.join(rel_root, file))
    
    return structure

def read_documentation_files(docs_path, max_files=50):
    """Lee los archivos de documentaci√≥n existentes"""
    docs_content = {}
    docs_dir = Path(docs_path)
    
    # Buscar archivos .mdx y .md
    doc_files = list(docs_dir.rglob('*.mdx')) + list(docs_dir.rglob('*.md'))
    doc_files = [f for f in doc_files if not any(part.startswith('.') for part in f.parts)]
    
    print(f"üìö Encontrados {len(doc_files)} archivos de documentaci√≥n")
    
    for doc_file in doc_files[:max_files]:
        try:
            rel_path = doc_file.relative_to(docs_dir)
            with open(doc_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # Limitar a primeros 2000 caracteres por archivo
                docs_content[str(rel_path)] = content[:2000] if len(content) > 2000 else content
        except Exception as e:
            print(f"‚ö†Ô∏è  Error leyendo {doc_file}: {e}")
    
    return docs_content

def analyze_architecture_files(repos_path):
    """Analiza archivos clave de arquitectura en los repos"""
    architecture = {
        "services": [],
        "infrastructure": [],
        "apis": [],
        "configs": []
    }
    
    repos_dir = Path(repos_path)
    
    # Buscar archivos importantes
    important_patterns = [
        "**/package.json",
        "**/README.md",
        "**/*.tf",
        "**/docker-compose.yml",
        "**/Dockerfile",
        "**/kong.yml"
    ]
    
    for pattern in important_patterns:
        for file in repos_dir.rglob(pattern):
            if not any(part.startswith('.') or part == 'node_modules' for part in file.parts):
                rel_path = file.relative_to(repos_dir)
                category = categorize_file(str(rel_path))
                
                try:
                    with open(file, 'r', encoding='utf-8') as f:
                        content = f.read()[:1000]  # Primeros 1000 chars
                        architecture[category].append({
                            "file": str(rel_path),
                            "preview": content
                        })
                except:
                    pass
    
    return architecture

def categorize_file(filepath):
    """Categoriza un archivo seg√∫n su tipo"""
    if 'package.json' in filepath or 'Dockerfile' in filepath:
        return 'services'
    elif '.tf' in filepath or 'infrastructure' in filepath:
        return 'infrastructure'
    elif 'kong' in filepath or 'api' in filepath.lower():
        return 'apis'
    else:
        return 'configs'

def create_comprehensive_prompt(docs_content, architecture, docs_structure, analysis_depth):
    """Crea un prompt comprehensivo para Claude"""
    
    prompt = f"""Eres un arquitecto de software SENIOR y auditor de documentaci√≥n con 15 a√±os de experiencia evaluando proyectos enterprise.

**OBJETIVO CR√çTICO: SCORE 9+ / 10**

Sistema: RetroGameCloud - Plataforma de juegos retro con microservicios en AWS/Kubernetes

**CRITERIOS ESTRICTOS PARA SCORE 9+:**
1. ‚úÖ CERO duplicaci√≥n - cada concepto documentado UNA vez
2. ‚úÖ Numeraci√≥n 100% consistente (X.Y. T√≠tulo en TODOS los archivos)
3. ‚úÖ Diagramas arquitectura completos (AWS, microservicios, flujos de datos)
4. ‚úÖ Runbooks operacionales detallados paso a paso
5. ‚úÖ Pol√≠ticas de seguridad y compliance documentadas
6. ‚úÖ APIs con schemas OpenAPI completos y ejemplos
7. ‚úÖ Disaster recovery y backup testeable documentado
8. ‚úÖ Gu√≠as end-to-end para desarrolladores nuevos
9. ‚úÖ Sin archivos de plantilla/ejemplo sin personalizar
10. ‚úÖ Profundidad t√©cnica enterprise en cada secci√≥n

**S√â CR√çTICO Y EXIGENTE** - La documentaci√≥n enterprise debe ser impecable.

## DOCUMENTACI√ìN ACTUAL

Total de archivos: {len(docs_content)}

### Estructura de documentaci√≥n:
{json.dumps(docs_structure, indent=2)}

### Contenido de documentaci√≥n (muestra):
"""
    
    # A√±adir muestra de docs
    for i, (filepath, content) in enumerate(list(docs_content.items())[:15]):
        prompt += f"\n#### {filepath}\n```\n{content[:500]}...\n```\n"
    
    prompt += f"""

## ARQUITECTURA DEL SISTEMA

### Servicios identificados:
{json.dumps([s['file'] for s in architecture['services'][:10]], indent=2)}

### Infraestructura:
{json.dumps([i['file'] for i in architecture['infrastructure'][:10]], indent=2)}

### APIs y Gateway:
{json.dumps([a['file'] for a in architecture['apis'][:10]], indent=2)}

## AN√ÅLISIS REQUERIDO (Profundidad: {analysis_depth})

Analiza TODO y prop√≥n mejoras en:

1. **ESTRUCTURA Y ORGANIZACI√ìN**
   - ¬øLa estructura actual tiene sentido?
   - ¬øFalta alguna secci√≥n importante?
   - ¬øHay que reorganizar o consolidar secciones?

2. **CONTENIDO Y GAPS**
   - ¬øQu√© documentaci√≥n cr√≠tica falta?
   - ¬øQu√© aspectos est√°n mal documentados?
   - ¬øQu√© ejemplos o tutoriales faltan?

3. **CONSOLIDACI√ìN Y REORGANIZACI√ìN (PRIORIDAD M√ÅXIMA)**
   - ¬øHay archivos duplicados o con contenido similar que deber√≠an fusionarse?
   - ¬øHay p√°ginas sin numeraci√≥n correcta (formato X.Y. T√≠tulo)?
   - ¬øArchivos en ubicaciones incorrectas que deben moverse?
   - ¬øContenido redundante que debe eliminarse?
   - ¬øEstructura de navegaci√≥n confusa que necesita simplificaci√≥n?

4. **DIAGRAMAS Y VISUALIZACIONES**
   - ¬øQu√© diagramas de arquitectura se necesitan? (especifica tipo: secuencia, componentes, flujo, etc)
   - ¬øQu√© visualizaciones ayudar√≠an? (gr√°ficos, tablas comparativas, etc)
   - Prop√≥n contenido exacto en Mermaid.js

5. **MEJORAS DE CALIDAD**
   - Inconsistencias en estilo o formato
   - Informaci√≥n desactualizada o contradictoria
   - Mejoras en claridad y usabilidad

**IMPORTANTE**: ANTES de crear archivos nuevos, verifica si ya existe contenido similar que puede mejorarse o consolidarse. Prioriza MODIFICAR y REORGANIZAR sobre CREAR.

## FORMATO DE RESPUESTA

**IMPORTANTE: TODO el contenido debe estar en espa√±ol de Espa√±a (castellano), incluyendo t√≠tulos, descripciones, contenido propuesto y diagramas. Usa terminolog√≠a t√©cnica en espa√±ol cuando exista traducci√≥n est√°ndar (por ejemplo: "Despliegue" en lugar de "Deployment", "Autenticaci√≥n" en lugar de "Authentication", etc.).**

Responde en JSON puro (sin markdown, sin bloques ```):

{{
  "analysis_summary": "Resumen EN ESPA√ëOL (m√°x 150 chars)",
  "overall_score": 7.5,
  "improvements": [
    {{
      "priority": "high|medium|low",
      "category": "structure|content|diagrams|quality",
      "title": "T√≠tulo EN ESPA√ëOL (m√°x 70 chars)",
      "description": "Descripci√≥n EN ESPA√ëOL (m√°x 180 chars)",
      "files_to_create": [],
      "files_to_modify": ["archivo.mdx"],
      "files_to_delete": [],
      "proposed_content": "",
      "mermaid_diagram": "",
      "rationale": "Justificaci√≥n EN ESPA√ëOL (m√°x 100 chars)"
    }}
  ],
  "new_sections": [],
  "diagrams_needed": [],
  "quick_wins": ["Mejoras r√°pidas EN ESPA√ëOL"],
  "critical_gaps": ["Gaps cr√≠ticos EN ESPA√ëOL"]
}}

**SCORING GUIDELINES:**
- Score 9.0-10.0: Documentaci√≥n enterprise perfecta, referencia de la industria
- Score 8.0-8.9: Excelente, solo mejoras menores pendientes
- Score 7.0-7.9: Buena, con algunos gaps que llenar
- Score 6.0-6.9: Aceptable, necesita consolidaci√≥n y mejoras
- Score <6.0: Requiere trabajo significativo

**ACTUAL STATE AFTER PR #28:**
- ‚úÖ Runbooks creados (infrastructure/runbooks.mdx)
- ‚úÖ Security policies creados (infrastructure/security-policies.mdx)
- ‚úÖ 13 archivos duplicados ELIMINADOS
- ‚úÖ 37 archivos mejorados
- ‚ö†Ô∏è  A√∫n pueden quedar archivos por consolidar

**SI LA DOCUMENTACI√ìN CUMPLE 8+ de los 10 criterios, el score debe ser 8.5-9.0+**

**REGLAS CR√çTICAS PARA JSON V√ÅLIDO (OBLIGATORIO):**

‚ö†Ô∏è LONGITUD M√ÅXIMA ESTRICTA:
- analysis_summary: M√ÅXIMO 150 caracteres
- title: M√ÅXIMO 70 caracteres
- description: M√ÅXIMO 180 caracteres
- proposed_content: DEJAR VAC√çO "" (no incluir contenido)
- mermaid_diagram: DEJAR VAC√çO "" (no incluir diagramas)
- rationale: M√ÅXIMO 100 caracteres

üö® FORMATO JSON CR√çTICO:
1. NO incluyas bloques de c√≥digo en proposed_content
2. NO incluyas saltos de l√≠nea (\n) en ning√∫n string
3. proposed_content y mermaid_diagram: usa "" vac√≠o
4. Si algo es largo, RESUME o usa ""
5. M√°ximo 8-10 mejoras totales

üéØ PRIORIDAD ABSOLUTA: CONSOLIDACI√ìN PRIMERO
Cuando detectes duplicaci√≥n:
- files_to_delete: ["archivo1.mdx", "archivo2.mdx"] ‚Üê OBLIGATORIO
- files_to_modify: ["archivo-destino.mdx"] ‚Üê donde se consolida
- category: "structure"
- priority: "high"
- description: "Fusionar X e Y en Z, eliminar duplicados"

üí° ESTRATEGIA:
1. Identifica 2-3 consolidaciones cr√≠ticas (alta prioridad)
2. Identifica 3-4 correcciones de numeraci√≥n
3. Identifica 2-3 mejoras de contenido existente
4. Prop√≥n 1-2 archivos nuevos SOLO si son esenciales
TOTAL: M√°ximo 10-12 mejoras

RECUERDA: 
- TODO en espa√±ol de Espa√±a
- S√â BREVE Y PRECISO
- Prioriza CONSOLIDAR > MEJORAR > CREAR
- Strings cortos = JSON v√°lido
"""
    
    return prompt

def analyze_with_claude(client, docs_content, architecture, docs_structure, analysis_depth):
    """Realiza el an√°lisis con Claude"""
    
    prompt = create_comprehensive_prompt(docs_content, architecture, docs_structure, analysis_depth)
    
    print(f"ü§ñ Enviando an√°lisis a Claude Sonnet 4.5...")
    print(f"üìä Tokens estimados: ~{len(prompt) // 4}")
    
    try:
        message = client.messages.create(
            model="claude-sonnet-4-5-20250929",
            max_tokens=16384,  # Aumentado para respuestas completas sin truncar
            temperature=0.3,  # M√°s determinista para JSON consistente
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        response_text = message.content[0].text.strip()
        
        print(f"‚úÖ Respuesta recibida ({len(response_text)} chars)")
        print(f"üìÑ Primeros 1000 caracteres de la respuesta:")
        print(response_text[:1000])
        print(f"\nüìÑ √öltimos 500 caracteres de la respuesta:")
        print(response_text[-500:])
        
        # Limpiar markdown code blocks si existen
        json_text = response_text
        if "```json" in json_text:
            print("üîç Detectado bloque de c√≥digo markdown ```json, extrayendo...")
            json_start = json_text.find("```json") + 7
            json_end = json_text.find("```", json_start)
            if json_end == -1:
                json_end = len(json_text)
            json_text = json_text[json_start:json_end].strip()
            print(f"‚úÖ JSON extra√≠do de markdown, longitud: {len(json_text)} caracteres")
            print(f"üîç Primeros 200 chars despu√©s de extraer: {json_text[:200]}")
        elif "```" in json_text:
            print("üîç Detectado bloque de c√≥digo gen√©rico, extrayendo...")
            json_start = json_text.find("```") + 3
            json_end = json_text.find("```", json_start)
            if json_end == -1:
                json_end = len(json_text)
            json_text = json_text[json_start:json_end].strip()
            print(f"‚úÖ JSON extra√≠do de bloque gen√©rico, longitud: {len(json_text)} caracteres")
        
        # NUEVO: Limpieza agresiva del JSON antes de parsear
        print("üßπ Limpiando JSON...")
        
        # Eliminar saltos de l√≠nea dentro de strings (causa principal del problema)
        # Buscar patrones como "text\n  more text" y reemplazar por "text more text"
        import re
        
        # Paso 1: Encontrar todos los strings y limpiarlos
        def clean_json_string(match):
            content = match.group(1)
            # Reemplazar saltos de l√≠nea y m√∫ltiples espacios por un solo espacio
            cleaned = re.sub(r'\s+', ' ', content)
            # Limitar longitud si es muy largo
            if len(cleaned) > 300:
                cleaned = cleaned[:297] + "..."
            return f'"{cleaned}"'
        
        # Limpiar strings entre comillas que contengan saltos de l√≠nea
        json_text = re.sub(r'"([^"]*(?:\n[^"]*)*)"', clean_json_string, json_text)
        
        print(f"‚úÖ JSON limpiado, longitud final: {len(json_text)} caracteres")
        
        # Intentar parsear
        try:
            result = json.loads(json_text)
            print("‚úÖ JSON parseado correctamente")
            return result
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è  Error parseando JSON: {e}")
            print(f"üìÑ Error en posici√≥n: l√≠nea {e.lineno}, columna {e.colno}")
            print(f"üìÑ Primeros 500 chars del JSON:")
            print(json_text[:500])
            print(f"\nüìÑ √öltimos 500 chars del JSON:")
            print(json_text[-500:])
            
            # Intentar reparar el JSON con estrategias incrementales
            try:
                print("üîß Estrategia 1: Reparaci√≥n con json-repair...")
                repaired = repair_json(json_text)
                result = json.loads(repaired)
                print("‚úÖ JSON reparado exitosamente con json-repair")
                return result
            except Exception as repair_error_1:
                print(f"‚ùå json-repair fall√≥: {repair_error_1}")
                
                # Estrategia 2: Truncar en el √∫ltimo } v√°lido
                try:
                    print("üîß Estrategia 2: Buscar √∫ltima llave v√°lida...")
                    last_brace = json_text.rfind('}')
                    if last_brace > 0:
                        truncated = json_text[:last_brace + 1]
                        result = json.loads(truncated)
                        print(f"‚úÖ JSON parseado truncando a posici√≥n {last_brace}")
                        return result
                except Exception as repair_error_2:
                    print(f"‚ùå Truncado fall√≥: {repair_error_2}")
                    
                    # Estrategia 3: Retornar estructura m√≠nima
                    print("‚ö†Ô∏è  Usando estructura de an√°lisis m√≠nima por defecto")
                    return {
                        "analysis_summary": "Error parseando respuesta de Claude",
                        "critical_gaps": [],
                        "improvements": [],
                        "new_pages_needed": []
                    }
            
    except Exception as e:
        print(f"‚ùå Error en an√°lisis: {e}")
        return None

def generate_improvements_report(analysis_result, output_path):
    """Genera reporte de mejoras en Markdown"""
    
    if not analysis_result:
        return False
    
    report = f"""# ü§ñ An√°lisis Inteligente de Documentaci√≥n

**Fecha**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Generado por**: Claude Sonnet 4.5  
**Puntuaci√≥n General**: {analysis_result.get('overall_score', 'N/A')}/10

## üìä Resumen Ejecutivo

{analysis_result.get('analysis_summary', 'Sin resumen')}

## üéØ Mejoras Prioritarias

"""
    
    improvements = analysis_result.get('improvements', [])
    
    # Agrupar por prioridad
    for priority in ['high', 'medium', 'low']:
        priority_items = [imp for imp in improvements if imp.get('priority') == priority]
        
        if priority_items:
            priority_label = {"high": "Alta ‚ö°", "medium": "Media üìå", "low": "Baja üí°"}[priority]
            report += f"\n### Prioridad {priority_label}\n\n"
            
            for imp in priority_items:
                report += f"#### {imp.get('title', 'Sin t√≠tulo')}\n\n"
                report += f"**Categor√≠a**: {imp.get('category', 'N/A')}  \n"
                report += f"**Descripci√≥n**: {imp.get('description', '')}  \n"
                report += f"**Raz√≥n**: {imp.get('rationale', '')}  \n\n"
                
                if imp.get('files_to_create'):
                    report += f"**Archivos a crear**: {', '.join(imp['files_to_create'])}  \n"
                if imp.get('files_to_modify'):
                    report += f"**Archivos a modificar**: {', '.join(imp['files_to_modify'])}  \n"
                if imp.get('mermaid_diagram'):
                    report += f"\n**Diagrama propuesto**:\n```mermaid\n{imp['mermaid_diagram']}\n```\n\n"
                
                report += "\n---\n\n"
    
    # Nuevas secciones
    new_sections = analysis_result.get('new_sections', [])
    if new_sections:
        report += "\n## üìÅ Nuevas Secciones Propuestas\n\n"
        for section in new_sections:
            # Validar que section sea un dict
            if isinstance(section, str):
                report += f"- {section}\n"
                continue
                
            report += f"### {section.get('name', 'Sin nombre')}\n\n"
            report += f"{section.get('description', '')}  \n\n"
            
            files = section.get('files', [])
            if files:
                report += "**Archivos**:\n"
                for file in files:
                    if isinstance(file, dict):
                        report += f"- `{file.get('filename', '')}`: {file.get('title', '')}  \n"
                    else:
                        report += f"- {file}\n"
                report += "\n"
    
    # Diagramas necesarios
    diagrams = analysis_result.get('diagrams_needed', [])
    if diagrams:
        report += "\n## üìà Diagramas Requeridos\n\n"
        for diag in diagrams:
            # Validar que diag sea un diccionario
            if isinstance(diag, str):
                report += f"- {diag}\n"
                continue
            
            report += f"### {diag.get('title', 'Diagrama')}\n\n"
            report += f"**Tipo**: {diag.get('type', 'N/A')}  \n"
            report += f"**Ubicaci√≥n**: {diag.get('location', 'N/A')}  \n"
            report += f"**Descripci√≥n**: {diag.get('description', '')}  \n\n"
            
            if diag.get('mermaid_code'):
                report += f"{diag['mermaid_code']}\n\n"
    
    # Quick wins
    quick_wins = analysis_result.get('quick_wins', [])
    if quick_wins:
        report += "\n## ‚ö° Quick Wins\n\n"
        for win in quick_wins:
            report += f"- {win}  \n"
    
    report += "\n\n---\n*An√°lisis generado autom√°ticamente*\n"
    
    # Guardar reporte
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"‚úÖ Reporte generado: {output_path}")
    return True

def main():
    parser = argparse.ArgumentParser(description='Intelligent Documentation Analyzer')
    parser.add_argument('--docs-path', required=True, help='Path to docs repository')
    parser.add_argument('--repos-path', required=True, help='Path to source repositories')
    parser.add_argument('--depth', default='full', choices=['quick', 'full', 'deep'])
    parser.add_argument('--output', default='analysis-results.json')
    
    args = parser.parse_args()
    
    api_key = os.environ.get('ANTHROPIC_API_KEY')
    if not api_key:
        print("‚ùå ANTHROPIC_API_KEY no configurada")
        sys.exit(1)
    
    print("üöÄ Iniciando an√°lisis inteligente de documentaci√≥n...")
    print(f"üìÇ Docs: {args.docs_path}")
    print(f"üìÇ Repos: {args.repos_path}")
    print(f"üîç Profundidad: {args.depth}")
    
    # 1. Escanear estructura
    print("\nüìä Escaneando estructura...")
    docs_structure = scan_directory_structure(args.docs_path)
    print(f"   ‚úì {len(docs_structure['files'])} archivos, {len(docs_structure['dirs'])} directorios")
    
    # 2. Leer documentaci√≥n
    print("\nüìö Leyendo documentaci√≥n...")
    docs_content = read_documentation_files(args.docs_path)
    print(f"   ‚úì {len(docs_content)} archivos procesados")
    
    # 3. Analizar arquitectura
    print("\nüèóÔ∏è  Analizando arquitectura...")
    architecture = analyze_architecture_files(args.repos_path)
    print(f"   ‚úì {len(architecture['services'])} servicios, {len(architecture['infrastructure'])} infra files")
    
    # 4. An√°lisis con Claude
    print("\nü§ñ Ejecutando an√°lisis con Claude AI...")
    client = anthropic.Anthropic(api_key=api_key)
    
    analysis_result = analyze_with_claude(
        client, 
        docs_content, 
        architecture, 
        docs_structure, 
        args.depth
    )
    
    if not analysis_result:
        print("‚ùå An√°lisis fall√≥")
        sys.exit(1)
    
    # 5. Guardar resultados
    print(f"\nüíæ Guardando resultados en {args.output}...")
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(analysis_result, f, indent=2, ensure_ascii=False)
    
    # 6. Generar reporte
    print("\nüìù Generando reporte de mejoras...")
    if generate_improvements_report(analysis_result, 'IMPROVEMENTS.md'):
        print("‚úÖ Reporte generado: IMPROVEMENTS.md")
    
    # 7. Resumen
    improvements_count = len(analysis_result.get('improvements', []))
    diagrams_count = len(analysis_result.get('diagrams_needed', []))
    sections_count = len(analysis_result.get('new_sections', []))
    
    print(f"\nüéâ An√°lisis completado!")
    print(f"   üìã {improvements_count} mejoras propuestas")
    print(f"   üìä {diagrams_count} diagramas recomendados")
    print(f"   üìÅ {sections_count} secciones nuevas sugeridas")
    print(f"   ‚≠ê Puntuaci√≥n: {analysis_result.get('overall_score', 'N/A')}/10")

if __name__ == '__main__':
    main()
